{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "drug_intake_bert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "colab_type": "code",
        "id": "CIJurNMZ5-pF",
        "outputId": "87cc687c-138d-48ee-dc48-530532032d93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "colab_type": "code",
        "id": "dKLl4jtP6LdV",
        "outputId": "b9039c90-7dab-4a7a-9cfa-08cdaf730050"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 549_data.zip\t   'How to get started with Drive.pdf'\n",
            " bert_models\t    model.ckpt-0.data-00000-of-00001\n",
            "'Colab Notebooks'   model.ckpt-500.data-00000-of-00001\n"
          ]
        }
      ],
      "source": [
        "!ls 'gdrive/My Drive'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "colab_type": "code",
        "id": "qObpfuji6Zmm",
        "outputId": "b1cbe4ed-9d5f-43fc-d509-7c693a75d71f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  gdrive/My Drive/549_data.zip\n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ],
      "source": [
        "!unzip -n 'gdrive/My Drive/549_data.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "I9Ij0uUU68wz",
        "outputId": "c32b15e9-acb8-41c7-fc03-9c02712cbc0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gdrive\tsample_data  test.csv  train.csv\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "colab_type": "code",
        "id": "hsZvic2YxnTz",
        "outputId": "3104bf7f-068a-41e9-c437-f77f1e47fb44"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "import tensorflow_hub as hub\n",
        "from datetime import datetime\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "colab_type": "code",
        "id": "jviywGyWyKsA",
        "outputId": "8a818470-d6cf-4128-e6cf-2ca6ce89140f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\r\u001b[K     |████▉                           | 10kB 32.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 30kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 40kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 51kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 61kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install bert-tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "hhbGEfwgdEtw"
      },
      "outputs": [],
      "source": [
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "both",
        "colab": {},
        "colab_type": "code",
        "id": "US_EAnICvP7f"
      },
      "outputs": [],
      "source": [
        "OUTPUT_DIR = 'outputs'\n",
        "\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "SfVkTKw8sL5M",
        "outputId": "0430d91f-199d-43c9-e5f2-fd80db574ea3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gdrive\toutputs  sample_data  test.csv\ttrain.csv\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pmFYvkylMwXn"
      },
      "source": [
        "#Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0yMi1HPr7uQ7"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('train.csv',sep='\\t')\n",
        "test = pd.read_csv('test.csv',sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "colab_type": "code",
        "id": "3bX_vW6o80L5",
        "outputId": "5632d574-e7fb-4afc-f18c-b0f6b9d7e1a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8336, 2) (6126, 2)\n",
            "                                                text  label\n",
            "0  @zj_marines that's good girl' I'm giving lily ...      3\n",
            "1      I am going to need a Xanax after this #debate      2\n",
            "2   My back freaking hurts wish I could pop a Xanax       2\n",
            "3  Im miserably tired but can't sleep and still w...      1\n",
            "4  the amount of ibuprofen i take is absolutely h...      2\n",
            "                                                text  label\n",
            "0  Sooooo I just realized my baby haven't been sl...      3\n",
            "1  @caitbateman1 hasn't mentioned it once. Won't ...      3\n",
            "2  My mouth is really irritating me , need some i...      2\n",
            "3                             That clonazepam got me      1\n",
            "4                       ibuprofen, hot tea & a bath       3\n"
          ]
        }
      ],
      "source": [
        "print(train.shape, test.shape)\n",
        "print(train.head())\n",
        "print(test.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "IuMOGwFui4it"
      },
      "outputs": [],
      "source": [
        "DATA_COLUMN = 'text'\n",
        "LABEL_COLUMN = 'label'\n",
        "\n",
        "label_list = [1, 2, 3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V399W0rqNJ-Z"
      },
      "source": [
        "\n",
        "- `text_a` is the input\n",
        "- `text_b` is used for translation or similar tasks. \n",
        "- `label` is the label... \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "p9gEt5SmM6i6"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# all training data\n",
        "all_train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "\n",
        "train_part , validation_part = train_test_split(train, test_size=0.1, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "train_InputExamples = train_part.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "\n",
        "\n",
        "validation_InputExamples = validation_part.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "\n",
        "\n",
        "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "NibJ7fomvHmA",
        "outputId": "d1f4c80f-47b8-4392-dc47-7246be7d791a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((8336,), (7502,), (834,), (6126,))"
            ]
          },
          "execution_count": 15,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_train_InputExamples.shape,  train_InputExamples.shape,  validation_InputExamples.shape, test_InputExamples.shape "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "IhJSe0QHNG7U"
      },
      "outputs": [],
      "source": [
        "# This is a path to an uncased (all lowercase) version of BERT\n",
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "\n",
        "def build_tokenizer_from_hub_module():\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "      \n",
        "  return bert.tokenization.FullTokenizer(\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = build_tokenizer_from_hub_module()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0OEzfFIt6GIc"
      },
      "source": [
        "These below are needed for Bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "LL5W8gEGRTAf"
      },
      "outputs": [],
      "source": [
        "# We'll set sequences to be at most 128 tokens long.\n",
        "MAX_SEQ_LENGTH = 50\n",
        "# Convert our train and test features to InputFeatures that BERT understands.\n",
        "\n",
        "all_train_features = bert.run_classifier.convert_examples_to_features(all_train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "\n",
        "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "validation_features = bert.run_classifier.convert_examples_to_features(validation_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "1ByHCH7GwQB9",
        "outputId": "104dd008-c1d2-48ac-ff1f-bcc9b7e9ebf5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8336, 7502, 834, 6126)"
            ]
          },
          "execution_count": 18,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(all_train_features), len(train_features),  len(validation_features), len(test_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ccp5trMwRtmr"
      },
      "source": [
        "#Getting a model\n",
        "\n",
        "Load Bert from tf hub and add a layer with 3 units for classification.\n",
        "Then fine tune the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "6o2a5ZIvRcJq"
      },
      "outputs": [],
      "source": [
        "def make_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels):\n",
        "\n",
        "  bert_module = hub.Module(\n",
        "      BERT_MODEL_HUB,\n",
        "      trainable=True)\n",
        "      # trainable=False)\n",
        "  bert_inputs = dict(\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      segment_ids=segment_ids)\n",
        "  bert_outputs = bert_module(\n",
        "      inputs=bert_inputs,\n",
        "      signature=\"tokens\",\n",
        "      as_dict=True)\n",
        "\n",
        "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
        "  # Use \"sequence_outputs\" for token-level output.\n",
        "  output_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "  # instantiate our own layer to tune for politeness data.\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "\n",
        "    # Dropout helps prevent overfitting\n",
        "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    # Convert labels into one-hot encoding\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
        "    if is_predicting:\n",
        "      return (predicted_labels, log_probs)\n",
        "\n",
        "    # If we're train/eval, compute loss between predicted and actual label\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "    return (loss, predicted_labels, log_probs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qpE0ZIDOCQzE"
      },
      "source": [
        "Next we'll wrap our model function in a `model_fn_builder` function that adapts our model to work for training, evaluation, and prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FnH-AnOQ9KKW"
      },
      "outputs": [],
      "source": [
        "# model_fn_builder actually makes our model function\n",
        "# using the passed parameters for num_labels, learning_rate, etc.\n",
        "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
        "                     num_warmup_steps):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "\n",
        "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "    \n",
        "    # TRAIN and EVAL\n",
        "    if not is_predicting:\n",
        "\n",
        "      (loss, predicted_labels, log_probs) = make_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      train_op = bert.optimization.create_optimizer(\n",
        "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "\n",
        "      # Calculate evaluation metrics. \n",
        "      def metric_fn(label_ids, predicted_labels):\n",
        "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "        # f1_score = tf.contrib.metrics.f1_score(\n",
        "        #     label_ids,\n",
        "        #     predicted_labels)\n",
        "        # auc = tf.metrics.auc(\n",
        "        #     label_ids,\n",
        "        #     predicted_labels)\n",
        "        recall = tf.metrics.recall(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        precision = tf.metrics.precision(\n",
        "            label_ids,\n",
        "            predicted_labels) \n",
        "        true_pos = tf.metrics.true_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        true_neg = tf.metrics.true_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)   \n",
        "        false_pos = tf.metrics.false_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)  \n",
        "        false_neg = tf.metrics.false_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            # \"f1_score\": f1_score,\n",
        "            # \"auc\": auc,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"true_positives\": true_pos,\n",
        "            \"true_negatives\": true_neg,\n",
        "            \"false_positives\": false_pos,\n",
        "            \"false_negatives\": false_neg\n",
        "        }\n",
        "\n",
        "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "\n",
        "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode,\n",
        "          loss=loss,\n",
        "          train_op=train_op)\n",
        "      else:\n",
        "          return tf.estimator.EstimatorSpec(mode=mode,\n",
        "            loss=loss,\n",
        "            eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      (predicted_labels, log_probs) = make_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      predictions = {\n",
        "          'probabilities': log_probs,\n",
        "          'labels': predicted_labels\n",
        "      }\n",
        "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "  # Return the actual model function in the closure\n",
        "  return model_fn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "OjwJ4bTeWXD8"
      },
      "outputs": [],
      "source": [
        "# Compute train and warmup steps from batch size\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 10.0\n",
        "# Warmup is a period of time where hte learning rate \n",
        "# is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 500\n",
        "SAVE_SUMMARY_STEPS = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "emHf9GhfWBZ_"
      },
      "outputs": [],
      "source": [
        "# Compute # train and warmup steps from batch size\n",
        "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "oEJldMr3WYZa"
      },
      "outputs": [],
      "source": [
        "# Specify outpit directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "q_WebpS1X97v"
      },
      "outputs": [],
      "source": [
        "model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "estimator = tf.estimator.Estimator(\n",
        "  model_fn=model_fn,\n",
        "  config=run_config,\n",
        "  params={\"batch_size\": BATCH_SIZE})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1Pv2bAlOX_-K"
      },
      "outputs": [],
      "source": [
        "# input function for training.\n",
        "train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "    features=train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t6Nukby2EB6-"
      },
      "source": [
        "Must use GPUs to train."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "colab_type": "code",
        "id": "nucD4gluYJmK",
        "outputId": "250282a1-eaf1-43ca-d884-ad299c18770e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beginning Training!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training took time  0:07:52.533445\n"
          ]
        }
      ],
      "source": [
        "print(f'Beginning Training!')\n",
        "current_time = datetime.now()\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print(\"Training took time \", datetime.now() - current_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CmbLTVniARy3"
      },
      "source": [
        "Run Validation... cross val. is too expensive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "JIhejfpyJ8Bx"
      },
      "outputs": [],
      "source": [
        "validation_input_fn = run_classifier.input_fn_builder(\n",
        "    features=validation_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "colab_type": "code",
        "id": "PPVEXhNjYXC-",
        "outputId": "62d747d7-a71a-4bf9-e2fd-e47df89bedd2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eval_accuracy  :  0.8189449\n",
            "false_negatives  :  35.0\n",
            "false_positives  :  48.0\n",
            "loss  :  0.9372541\n",
            "precision  :  0.9296188\n",
            "recall  :  0.9476831\n",
            "true_negatives  :  117.0\n",
            "true_positives  :  634.0\n",
            "global_step  :  586\n"
          ]
        }
      ],
      "source": [
        "res = estimator.evaluate(input_fn=validation_input_fn, steps=None)\n",
        "for r in res:\n",
        "    print(r,' : ', res[r])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "OsrbTD2EJTVl"
      },
      "outputs": [],
      "source": [
        "def getPrediction(in_sentences):\n",
        "  labels = [1,2,3]\n",
        "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 1) for x in in_sentences] # here, \"\" is just a dummy label\n",
        "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
        "  predictions = estimator.predict(predict_input_fn)\n",
        "  return [(sentence, prediction['probabilities'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "z6DQfXKeFWVq"
      },
      "outputs": [],
      "source": [
        "y_true = validation_part['label']\n",
        "preds = getPrediction(validation_part['text'])\n",
        "y_pred = [x[2] for x in preds]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "colab_type": "code",
        "id": "BhlFpcmsNbs9",
        "outputId": "12617f4c-2a1e-4261-fe69-0af6a608e948"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.7763    0.7152    0.7445       165\n",
            "           2     0.7207    0.7917    0.7545       264\n",
            "           3     0.9133    0.8840    0.8984       405\n",
            "\n",
            "    accuracy                         0.8213       834\n",
            "   macro avg     0.8034    0.7969    0.7991       834\n",
            "weighted avg     0.8252    0.8213    0.8224       834\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_true, y_pred, digits=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ueKsULteiz1B"
      },
      "source": [
        "Once I determined my parameters, I train the model with all the training data and then use the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "colab_type": "code",
        "id": "bXwnb6c1Ejk3",
        "outputId": "70abb63e-6e01-49a8-d618-506faa8b1cd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beginning Training!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training took time  0:01:28.740454\n"
          ]
        }
      ],
      "source": [
        "# Compute # train and warmup steps from batch size\n",
        "num_train_steps = int(len(all_train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "# Specify outpit directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
        "\n",
        "model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "estimator = tf.estimator.Estimator(\n",
        "  model_fn=model_fn,\n",
        "  config=run_config,\n",
        "  params={\"batch_size\": BATCH_SIZE})\n",
        "\n",
        "# Input function for training. drop_remainder = True for using TPUs.\n",
        "train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "    features=all_train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=False)\n",
        "\n",
        "\n",
        "print(f'Beginning Training!')\n",
        "current_time = datetime.now()\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print(\"Training took time \", datetime.now() - current_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Py2Yn69O6_sg"
      },
      "outputs": [],
      "source": [
        "y_true = test['label']\n",
        "preds = getPrediction(test['text'])\n",
        "y_pred = [x[2] for x in preds]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "colab_type": "code",
        "id": "esCipTIiZ-_c",
        "outputId": "0326fc3e-334e-42ee-c186-b6242924a089"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.6963    0.7906    0.7404      1409\n",
            "           2     0.7713    0.6608    0.7118      2205\n",
            "           3     0.8297    0.8710    0.8499      2512\n",
            "\n",
            "    accuracy                         0.7769      6126\n",
            "   macro avg     0.7658    0.7741    0.7674      6126\n",
            "weighted avg     0.7780    0.7769    0.7750      6126\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_true, y_pred, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "colab_type": "code",
        "id": "7WqnigjoMMXh",
        "outputId": "f72958eb-c0c2-456b-c799-bbcc178ce170"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint\t\t\t\t     model.ckpt-500.index\n",
            "eval\t\t\t\t\t     model.ckpt-500.meta\n",
            "events.out.tfevents.1577614500.5828f8ef0782  model.ckpt-586.data-00000-of-00001\n",
            "graph.pbtxt\t\t\t\t     model.ckpt-586.index\n",
            "model.ckpt-0.data-00000-of-00001\t     model.ckpt-586.meta\n",
            "model.ckpt-0.index\t\t\t     model.ckpt-651.data-00000-of-00001\n",
            "model.ckpt-0.meta\t\t\t     model.ckpt-651.index\n",
            "model.ckpt-500.data-00000-of-00001\t     model.ckpt-651.meta\n"
          ]
        }
      ],
      "source": [
        "!ls outputs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7koPdMAyJlDc"
      },
      "outputs": [],
      "source": []
    }
  ]
}