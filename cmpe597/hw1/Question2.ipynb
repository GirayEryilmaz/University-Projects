{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2: [Multiclass Classification] [30 pts] Use Kerasâ€™ built-in\n",
    "Reuters dataset (from keras.datasets import reuters) to classify 46\n",
    "different topics. Use k-fold cross validation and show loss/accuracy\n",
    "plots by epoch.\n",
    "\t\n",
    "- Change number of layers, report the difference.\n",
    "\n",
    "\t\n",
    "- Increase number of hidden units, report the difference.\n",
    "\n",
    "\t\n",
    "- Decrease number of hidden units, report the difference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(histories_per_fold):\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes()\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('accuracy')\n",
    "    plt.title('acc vs loss, epoch by epoch')\n",
    "    accs = [sum(x)/len(histories_per_fold) for x in zip(*[history.history['acc'] for history in histories_per_fold])]\n",
    "    losses = [sum(x)/len(histories_per_fold) for x in zip(*[history.history['loss'] for history in histories_per_fold])]\n",
    "    val_accs = [sum(x)/len(histories_per_fold) for x in zip(*[history.history['val_acc'] for history in histories_per_fold])]\n",
    "    val_losses = [sum(x)/len(histories_per_fold) for x in zip(*[history.history['val_loss'] for history in histories_per_fold])]\n",
    "#     for history in histories_per_fold:\n",
    "#         plt.plot(history.history['acc'],history.history['loss'])\n",
    "    plt.plot(accs,losses)    \n",
    "    plt.plot(val_accs, val_losses)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, Y), _ = reuters.load_data(num_words=None, test_split=0)\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {}\n",
    "for key, value in word_index.items():\n",
    "    index_to_word[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "X = tokenizer.sequences_to_matrix(X, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 46"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider below like the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold no:0\n",
      "Train on 8959 samples, validate on 2269 samples\n",
      "Epoch 1/20\n",
      "8959/8959 [==============================] - 4s 409us/step - loss: 5.0887 - acc: 0.5892 - val_loss: 2.5930 - val_acc: 0.6659\n",
      "Epoch 2/20\n",
      "8959/8959 [==============================] - 3s 329us/step - loss: 2.2991 - acc: 0.6630 - val_loss: 2.1230 - val_acc: 0.6827\n",
      "Epoch 3/20\n",
      "8959/8959 [==============================] - 3s 329us/step - loss: 2.0403 - acc: 0.6773 - val_loss: 1.9681 - val_acc: 0.6919\n",
      "Epoch 4/20\n",
      "8959/8959 [==============================] - 3s 342us/step - loss: 1.9635 - acc: 0.6826 - val_loss: 1.9431 - val_acc: 0.6875\n",
      "Epoch 5/20\n",
      "8959/8959 [==============================] - 3s 321us/step - loss: 1.9111 - acc: 0.6827 - val_loss: 1.9396 - val_acc: 0.6884\n",
      "Epoch 6/20\n",
      "8959/8959 [==============================] - 3s 370us/step - loss: 1.8854 - acc: 0.6870 - val_loss: 1.8567 - val_acc: 0.6915\n",
      "Epoch 7/20\n",
      "8959/8959 [==============================] - 3s 380us/step - loss: 1.8661 - acc: 0.6875 - val_loss: 1.8301 - val_acc: 0.7034\n",
      "Epoch 8/20\n",
      "8959/8959 [==============================] - 3s 373us/step - loss: 1.8370 - acc: 0.6936 - val_loss: 1.8600 - val_acc: 0.6941\n",
      "Epoch 9/20\n",
      "8959/8959 [==============================] - 3s 347us/step - loss: 1.8125 - acc: 0.6898 - val_loss: 1.7870 - val_acc: 0.7021\n",
      "Epoch 10/20\n",
      "8959/8959 [==============================] - 3s 339us/step - loss: 1.7872 - acc: 0.6964 - val_loss: 1.8838 - val_acc: 0.6946\n",
      "Epoch 11/20\n",
      "8959/8959 [==============================] - 3s 367us/step - loss: 1.8188 - acc: 0.6980 - val_loss: 1.7727 - val_acc: 0.7060\n",
      "Epoch 12/20\n",
      "8959/8959 [==============================] - 4s 428us/step - loss: 1.7895 - acc: 0.6954 - val_loss: 1.7790 - val_acc: 0.7096\n",
      "Epoch 13/20\n",
      "8959/8959 [==============================] - 3s 324us/step - loss: 1.7821 - acc: 0.7007 - val_loss: 1.7852 - val_acc: 0.7096\n",
      "Epoch 14/20\n",
      "8959/8959 [==============================] - 4s 426us/step - loss: 1.7820 - acc: 0.7023 - val_loss: 1.7728 - val_acc: 0.7162\n",
      "Epoch 15/20\n",
      "8959/8959 [==============================] - 3s 294us/step - loss: 1.7603 - acc: 0.7014 - val_loss: 1.7662 - val_acc: 0.7184\n",
      "Epoch 16/20\n",
      "8959/8959 [==============================] - 3s 303us/step - loss: 1.7633 - acc: 0.7048 - val_loss: 1.7934 - val_acc: 0.7184\n",
      "Epoch 17/20\n",
      "8959/8959 [==============================] - 3s 317us/step - loss: 1.7483 - acc: 0.7086 - val_loss: 1.7798 - val_acc: 0.7122\n",
      "Epoch 18/20\n",
      "8959/8959 [==============================] - 3s 313us/step - loss: 1.7446 - acc: 0.7080 - val_loss: 1.7587 - val_acc: 0.7157\n",
      "Epoch 19/20\n",
      "8959/8959 [==============================] - 3s 372us/step - loss: 1.7593 - acc: 0.7118 - val_loss: 1.7703 - val_acc: 0.7193\n",
      "Epoch 20/20\n",
      "8959/8959 [==============================] - 4s 425us/step - loss: 1.7403 - acc: 0.7122 - val_loss: 1.7747 - val_acc: 0.7290\n",
      "Fold no:1\n",
      "Train on 8968 samples, validate on 2260 samples\n",
      "Epoch 1/20\n",
      "8968/8968 [==============================] - 4s 487us/step - loss: 5.1507 - acc: 0.5894 - val_loss: 2.6273 - val_acc: 0.6801\n",
      "Epoch 2/20\n",
      "8968/8968 [==============================] - 3s 355us/step - loss: 2.3442 - acc: 0.6562 - val_loss: 2.0555 - val_acc: 0.6934\n",
      "Epoch 3/20\n",
      "8968/8968 [==============================] - 3s 324us/step - loss: 2.0614 - acc: 0.6743 - val_loss: 1.9811 - val_acc: 0.6947\n",
      "Epoch 4/20\n",
      "8968/8968 [==============================] - 3s 317us/step - loss: 1.9659 - acc: 0.6787 - val_loss: 1.8551 - val_acc: 0.6956\n",
      "Epoch 5/20\n",
      "8968/8968 [==============================] - 3s 325us/step - loss: 1.9086 - acc: 0.6859 - val_loss: 1.8279 - val_acc: 0.6978\n",
      "Epoch 6/20\n",
      "8968/8968 [==============================] - 3s 319us/step - loss: 1.8713 - acc: 0.6848 - val_loss: 1.7869 - val_acc: 0.6942\n",
      "Epoch 7/20\n",
      "8968/8968 [==============================] - 4s 398us/step - loss: 1.8822 - acc: 0.6867 - val_loss: 1.8491 - val_acc: 0.6810\n",
      "Epoch 8/20\n",
      "8968/8968 [==============================] - 3s 367us/step - loss: 1.8450 - acc: 0.6891 - val_loss: 1.7371 - val_acc: 0.7013\n",
      "Epoch 9/20\n",
      "8968/8968 [==============================] - 3s 348us/step - loss: 1.8275 - acc: 0.6969 - val_loss: 1.7687 - val_acc: 0.7022\n",
      "Epoch 10/20\n",
      "8968/8968 [==============================] - 3s 368us/step - loss: 1.8208 - acc: 0.6949 - val_loss: 1.7495 - val_acc: 0.7124\n",
      "Epoch 11/20\n",
      "8968/8968 [==============================] - 3s 325us/step - loss: 1.8151 - acc: 0.6955 - val_loss: 1.7624 - val_acc: 0.6960\n",
      "Epoch 12/20\n",
      "8968/8968 [==============================] - 3s 321us/step - loss: 1.7947 - acc: 0.7015 - val_loss: 1.7288 - val_acc: 0.7124\n",
      "Epoch 13/20\n",
      "8968/8968 [==============================] - 3s 337us/step - loss: 1.7924 - acc: 0.6979 - val_loss: 1.7191 - val_acc: 0.7142\n",
      "Epoch 14/20\n",
      "8968/8968 [==============================] - 3s 329us/step - loss: 1.7958 - acc: 0.6980 - val_loss: 1.7217 - val_acc: 0.7186\n",
      "Epoch 15/20\n",
      "8968/8968 [==============================] - 3s 315us/step - loss: 1.7980 - acc: 0.7010 - val_loss: 1.7598 - val_acc: 0.7173\n",
      "Epoch 16/20\n",
      "8968/8968 [==============================] - 4s 395us/step - loss: 1.7762 - acc: 0.7053 - val_loss: 1.7735 - val_acc: 0.7080\n",
      "Epoch 17/20\n",
      "8968/8968 [==============================] - 3s 363us/step - loss: 1.7723 - acc: 0.7060 - val_loss: 1.6965 - val_acc: 0.7283\n",
      "Epoch 18/20\n",
      "8968/8968 [==============================] - 3s 327us/step - loss: 1.7527 - acc: 0.7116 - val_loss: 1.8401 - val_acc: 0.6872\n",
      "Epoch 19/20\n",
      "8968/8968 [==============================] - 3s 356us/step - loss: 1.7560 - acc: 0.7111 - val_loss: 1.6933 - val_acc: 0.7235\n",
      "Epoch 20/20\n",
      "8968/8968 [==============================] - 3s 342us/step - loss: 1.7411 - acc: 0.7149 - val_loss: 1.7179 - val_acc: 0.7310\n",
      "Fold no:2\n",
      "Train on 8986 samples, validate on 2242 samples\n",
      "Epoch 1/20\n",
      "8986/8986 [==============================] - 4s 393us/step - loss: 5.0586 - acc: 0.5849 - val_loss: 2.5344 - val_acc: 0.6762\n",
      "Epoch 2/20\n",
      "8986/8986 [==============================] - 3s 338us/step - loss: 2.3103 - acc: 0.6645 - val_loss: 2.0200 - val_acc: 0.6998\n",
      "Epoch 3/20\n",
      "8986/8986 [==============================] - 3s 336us/step - loss: 2.0477 - acc: 0.6753 - val_loss: 1.8811 - val_acc: 0.7003\n",
      "Epoch 4/20\n",
      "8986/8986 [==============================] - 3s 358us/step - loss: 1.9576 - acc: 0.6816 - val_loss: 1.8167 - val_acc: 0.6985\n",
      "Epoch 5/20\n",
      "8986/8986 [==============================] - 3s 386us/step - loss: 1.9096 - acc: 0.6852 - val_loss: 1.7720 - val_acc: 0.7012\n",
      "Epoch 6/20\n",
      "8986/8986 [==============================] - 3s 360us/step - loss: 1.8803 - acc: 0.6864 - val_loss: 1.7464 - val_acc: 0.7016\n",
      "Epoch 7/20\n",
      "8986/8986 [==============================] - 3s 340us/step - loss: 1.8603 - acc: 0.6874 - val_loss: 1.7617 - val_acc: 0.6936\n",
      "Epoch 8/20\n",
      "8986/8986 [==============================] - 3s 339us/step - loss: 1.8514 - acc: 0.6866 - val_loss: 1.7182 - val_acc: 0.7101\n",
      "Epoch 9/20\n",
      "8986/8986 [==============================] - 3s 331us/step - loss: 1.8361 - acc: 0.6885 - val_loss: 1.7288 - val_acc: 0.7101\n",
      "Epoch 10/20\n",
      "8986/8986 [==============================] - 3s 355us/step - loss: 1.8249 - acc: 0.6923 - val_loss: 1.6850 - val_acc: 0.7043\n",
      "Epoch 11/20\n",
      "8986/8986 [==============================] - 4s 408us/step - loss: 1.8081 - acc: 0.6951 - val_loss: 1.7086 - val_acc: 0.7087\n",
      "Epoch 12/20\n",
      "8986/8986 [==============================] - 5s 570us/step - loss: 1.8210 - acc: 0.6919 - val_loss: 1.8155 - val_acc: 0.7003\n",
      "Epoch 13/20\n",
      "8986/8986 [==============================] - 4s 400us/step - loss: 1.8007 - acc: 0.6935 - val_loss: 1.6853 - val_acc: 0.7226\n",
      "Epoch 14/20\n",
      "8986/8986 [==============================] - 4s 409us/step - loss: 1.7853 - acc: 0.6998 - val_loss: 1.6650 - val_acc: 0.7275\n",
      "Epoch 15/20\n",
      "8986/8986 [==============================] - 5s 560us/step - loss: 1.7916 - acc: 0.6996 - val_loss: 1.6666 - val_acc: 0.7297\n",
      "Epoch 16/20\n",
      "8986/8986 [==============================] - 5s 517us/step - loss: 1.7888 - acc: 0.7016 - val_loss: 1.6716 - val_acc: 0.7235\n",
      "Epoch 17/20\n",
      "8986/8986 [==============================] - 4s 428us/step - loss: 1.7827 - acc: 0.7052 - val_loss: 1.6721 - val_acc: 0.7333\n",
      "Epoch 18/20\n",
      "8986/8986 [==============================] - 3s 366us/step - loss: 1.7598 - acc: 0.7103 - val_loss: 1.6456 - val_acc: 0.7221\n",
      "Epoch 19/20\n",
      "8986/8986 [==============================] - 3s 387us/step - loss: 1.7566 - acc: 0.7124 - val_loss: 1.6399 - val_acc: 0.7440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "8986/8986 [==============================] - 3s 367us/step - loss: 1.7581 - acc: 0.7131 - val_loss: 1.6312 - val_acc: 0.7386\n",
      "Fold no:3\n",
      "Train on 8995 samples, validate on 2233 samples\n",
      "Epoch 1/20\n",
      "8995/8995 [==============================] - 4s 429us/step - loss: 5.1410 - acc: 0.5888 - val_loss: 2.5563 - val_acc: 0.6547\n",
      "Epoch 2/20\n",
      "8995/8995 [==============================] - 3s 372us/step - loss: 2.3129 - acc: 0.6621 - val_loss: 2.0217 - val_acc: 0.6798\n",
      "Epoch 3/20\n",
      "8995/8995 [==============================] - 4s 457us/step - loss: 2.0703 - acc: 0.6745 - val_loss: 1.9458 - val_acc: 0.6820\n",
      "Epoch 4/20\n",
      "8995/8995 [==============================] - 3s 385us/step - loss: 1.9616 - acc: 0.6826 - val_loss: 1.8650 - val_acc: 0.6874\n",
      "Epoch 5/20\n",
      "8995/8995 [==============================] - 3s 336us/step - loss: 1.9312 - acc: 0.6832 - val_loss: 1.8204 - val_acc: 0.6879\n",
      "Epoch 6/20\n",
      "8995/8995 [==============================] - 3s 364us/step - loss: 1.8973 - acc: 0.6866 - val_loss: 1.8021 - val_acc: 0.6950\n",
      "Epoch 7/20\n",
      "8995/8995 [==============================] - 4s 445us/step - loss: 1.8821 - acc: 0.6854 - val_loss: 1.7230 - val_acc: 0.6991\n",
      "Epoch 8/20\n",
      "8995/8995 [==============================] - 3s 376us/step - loss: 1.8483 - acc: 0.6895 - val_loss: 1.7367 - val_acc: 0.6964\n",
      "Epoch 9/20\n",
      "8995/8995 [==============================] - 3s 374us/step - loss: 1.8624 - acc: 0.6887 - val_loss: 1.7431 - val_acc: 0.7026\n",
      "Epoch 10/20\n",
      "8995/8995 [==============================] - 3s 388us/step - loss: 1.8328 - acc: 0.6963 - val_loss: 1.7777 - val_acc: 0.6959\n",
      "Epoch 11/20\n",
      "8995/8995 [==============================] - 3s 355us/step - loss: 1.8125 - acc: 0.7005 - val_loss: 1.6788 - val_acc: 0.7192\n",
      "Epoch 12/20\n",
      "8995/8995 [==============================] - 5s 594us/step - loss: 1.8107 - acc: 0.7011 - val_loss: 1.8018 - val_acc: 0.6892\n",
      "Epoch 13/20\n",
      "8995/8995 [==============================] - 4s 485us/step - loss: 1.8177 - acc: 0.6976 - val_loss: 1.6758 - val_acc: 0.7228\n",
      "Epoch 14/20\n",
      "8995/8995 [==============================] - 3s 320us/step - loss: 1.7987 - acc: 0.7017 - val_loss: 1.6626 - val_acc: 0.7143\n",
      "Epoch 15/20\n",
      "8995/8995 [==============================] - 3s 342us/step - loss: 1.7788 - acc: 0.7079 - val_loss: 1.6300 - val_acc: 0.7326\n",
      "Epoch 16/20\n",
      "8995/8995 [==============================] - 4s 485us/step - loss: 1.7910 - acc: 0.7049 - val_loss: 1.6695 - val_acc: 0.7134\n",
      "Epoch 17/20\n",
      "8995/8995 [==============================] - 4s 396us/step - loss: 1.7868 - acc: 0.7092 - val_loss: 1.6614 - val_acc: 0.7322\n",
      "Epoch 18/20\n",
      "8995/8995 [==============================] - 3s 380us/step - loss: 1.7765 - acc: 0.7091 - val_loss: 1.6403 - val_acc: 0.7421\n",
      "Epoch 19/20\n",
      "8995/8995 [==============================] - 3s 365us/step - loss: 1.7716 - acc: 0.7077 - val_loss: 1.6621 - val_acc: 0.7389\n",
      "Epoch 20/20\n",
      "8995/8995 [==============================] - 4s 432us/step - loss: 1.7642 - acc: 0.7118 - val_loss: 1.6681 - val_acc: 0.7309\n",
      "Fold no:4\n",
      "Train on 9004 samples, validate on 2224 samples\n",
      "Epoch 1/20\n",
      "9004/9004 [==============================] - 4s 491us/step - loss: 5.1351 - acc: 0.5883 - val_loss: 2.5164 - val_acc: 0.6722\n",
      "Epoch 2/20\n",
      "9004/9004 [==============================] - 4s 390us/step - loss: 2.2933 - acc: 0.6655 - val_loss: 2.0799 - val_acc: 0.6664\n",
      "Epoch 3/20\n",
      "9004/9004 [==============================] - 4s 417us/step - loss: 2.0507 - acc: 0.6753 - val_loss: 1.9358 - val_acc: 0.6879\n",
      "Epoch 4/20\n",
      "9004/9004 [==============================] - 3s 380us/step - loss: 1.9668 - acc: 0.6818 - val_loss: 1.8659 - val_acc: 0.6992\n",
      "Epoch 5/20\n",
      "9004/9004 [==============================] - 3s 378us/step - loss: 1.9217 - acc: 0.6810 - val_loss: 1.8346 - val_acc: 0.6951\n",
      "Epoch 6/20\n",
      "9004/9004 [==============================] - 4s 442us/step - loss: 1.8892 - acc: 0.6843 - val_loss: 1.7608 - val_acc: 0.6996\n",
      "Epoch 7/20\n",
      "9004/9004 [==============================] - 3s 367us/step - loss: 1.8580 - acc: 0.6870 - val_loss: 1.7478 - val_acc: 0.6974\n",
      "Epoch 8/20\n",
      "9004/9004 [==============================] - 4s 481us/step - loss: 1.8710 - acc: 0.6904 - val_loss: 1.7618 - val_acc: 0.7055\n",
      "Epoch 9/20\n",
      "9004/9004 [==============================] - 4s 439us/step - loss: 1.8367 - acc: 0.6908 - val_loss: 1.7360 - val_acc: 0.7041\n",
      "Epoch 10/20\n",
      "9004/9004 [==============================] - 3s 368us/step - loss: 1.8237 - acc: 0.6955 - val_loss: 1.7227 - val_acc: 0.7001\n",
      "Epoch 11/20\n",
      "9004/9004 [==============================] - 3s 364us/step - loss: 1.8118 - acc: 0.6952 - val_loss: 1.7193 - val_acc: 0.7073\n",
      "Epoch 12/20\n",
      "9004/9004 [==============================] - 4s 422us/step - loss: 1.8127 - acc: 0.6986 - val_loss: 1.7442 - val_acc: 0.7181\n",
      "Epoch 13/20\n",
      "9004/9004 [==============================] - 4s 402us/step - loss: 1.8146 - acc: 0.6957 - val_loss: 1.7460 - val_acc: 0.6996\n",
      "Epoch 14/20\n",
      "9004/9004 [==============================] - 3s 361us/step - loss: 1.8064 - acc: 0.6988 - val_loss: 1.7290 - val_acc: 0.7109\n",
      "Epoch 15/20\n",
      "9004/9004 [==============================] - 3s 368us/step - loss: 1.7924 - acc: 0.7006 - val_loss: 1.6886 - val_acc: 0.7172\n",
      "Epoch 16/20\n",
      "9004/9004 [==============================] - 3s 360us/step - loss: 1.7803 - acc: 0.7044 - val_loss: 1.6834 - val_acc: 0.7235\n",
      "Epoch 17/20\n",
      "9004/9004 [==============================] - 3s 364us/step - loss: 1.7703 - acc: 0.7086 - val_loss: 1.7245 - val_acc: 0.7244\n",
      "Epoch 18/20\n",
      "9004/9004 [==============================] - 3s 366us/step - loss: 1.7768 - acc: 0.7057 - val_loss: 1.6882 - val_acc: 0.7262\n",
      "Epoch 19/20\n",
      "9004/9004 [==============================] - 3s 367us/step - loss: 1.7749 - acc: 0.7064 - val_loss: 1.6690 - val_acc: 0.7311\n",
      "Epoch 20/20\n",
      "9004/9004 [==============================] - 3s 365us/step - loss: 1.7535 - acc: 0.7102 - val_loss: 1.6792 - val_acc: 0.7325\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "histories_per_fold = []\n",
    "# split training and validation sets\n",
    "for i, (train, test) in enumerate(kfold.split(X, Y)):\n",
    "    print(\"Fold no:{}\".format(i))\n",
    "    X_train = X[train]\n",
    "    X_test = X[test]\n",
    "    Y_test = pd.get_dummies(Y[test])\n",
    "    Y_train = pd.get_dummies(Y[train])\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, kernel_regularizer=l1(0.001), activation='relu', input_shape=(max_words,)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, kernel_regularizer=l1(0.001), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(46, activation='softmax'))\n",
    "    model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, Y_train, epochs=20, batch_size=32, verbose=1, validation_data=(X_test,Y_test))\n",
    "    histories_per_fold.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_plot(histories_per_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold no:0\n",
      "Train on 8959 samples, validate on 2269 samples\n",
      "Epoch 1/20\n",
      "8959/8959 [==============================] - 4s 478us/step - loss: 6.3048 - acc: 0.5363 - val_loss: 2.9608 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "8959/8959 [==============================] - 4s 428us/step - loss: 2.5112 - acc: 0.5761 - val_loss: 2.3243 - val_acc: 0.5884\n",
      "Epoch 3/20\n",
      "8959/8959 [==============================] - 4s 418us/step - loss: 2.2575 - acc: 0.5955 - val_loss: 2.2139 - val_acc: 0.6188\n",
      "Epoch 4/20\n",
      "8959/8959 [==============================] - 4s 394us/step - loss: 2.1714 - acc: 0.6181 - val_loss: 2.1265 - val_acc: 0.6399\n",
      "Epoch 5/20\n",
      "8959/8959 [==============================] - 3s 381us/step - loss: 2.1392 - acc: 0.6270 - val_loss: 2.1203 - val_acc: 0.6487\n",
      "Epoch 6/20\n",
      "8959/8959 [==============================] - 3s 376us/step - loss: 2.1020 - acc: 0.6317 - val_loss: 2.0782 - val_acc: 0.6457\n",
      "Epoch 7/20\n",
      "8959/8959 [==============================] - 3s 387us/step - loss: 2.0674 - acc: 0.6356 - val_loss: 2.0502 - val_acc: 0.6492\n",
      "Epoch 8/20\n",
      "8959/8959 [==============================] - 4s 437us/step - loss: 2.0597 - acc: 0.6333 - val_loss: 2.1177 - val_acc: 0.6435\n",
      "Epoch 9/20\n",
      "8959/8959 [==============================] - 4s 457us/step - loss: 2.0369 - acc: 0.6389 - val_loss: 2.0775 - val_acc: 0.6457\n",
      "Epoch 10/20\n",
      "8959/8959 [==============================] - 4s 429us/step - loss: 2.0347 - acc: 0.6361 - val_loss: 2.0415 - val_acc: 0.6509\n",
      "Epoch 11/20\n",
      "8959/8959 [==============================] - 4s 499us/step - loss: 2.0245 - acc: 0.6346 - val_loss: 2.0153 - val_acc: 0.6527\n",
      "Epoch 12/20\n",
      "8959/8959 [==============================] - 4s 502us/step - loss: 2.0158 - acc: 0.6388 - val_loss: 2.0543 - val_acc: 0.6540\n",
      "Epoch 13/20\n",
      "8959/8959 [==============================] - 4s 406us/step - loss: 2.0023 - acc: 0.6467 - val_loss: 2.0282 - val_acc: 0.6655\n",
      "Epoch 14/20\n",
      "8959/8959 [==============================] - 3s 385us/step - loss: 1.9983 - acc: 0.6513 - val_loss: 2.0150 - val_acc: 0.6602\n",
      "Epoch 15/20\n",
      "8959/8959 [==============================] - 3s 337us/step - loss: 1.9891 - acc: 0.6485 - val_loss: 2.0155 - val_acc: 0.6611\n",
      "Epoch 16/20\n",
      "8959/8959 [==============================] - 5s 583us/step - loss: 1.9828 - acc: 0.6496 - val_loss: 2.0078 - val_acc: 0.6664\n",
      "Epoch 17/20\n",
      "8959/8959 [==============================] - 5s 575us/step - loss: 1.9828 - acc: 0.6546 - val_loss: 2.0358 - val_acc: 0.6664\n",
      "Epoch 18/20\n",
      "8959/8959 [==============================] - 4s 393us/step - loss: 1.9832 - acc: 0.6544 - val_loss: 2.0266 - val_acc: 0.6668\n",
      "Epoch 19/20\n",
      "8959/8959 [==============================] - 4s 436us/step - loss: 1.9770 - acc: 0.6563 - val_loss: 2.0227 - val_acc: 0.6739\n",
      "Epoch 20/20\n",
      "8959/8959 [==============================] - 6s 646us/step - loss: 1.9848 - acc: 0.6554 - val_loss: 2.0038 - val_acc: 0.6770\n",
      "Fold no:1\n",
      "Train on 8968 samples, validate on 2260 samples\n",
      "Epoch 1/20\n",
      "8968/8968 [==============================] - 5s 536us/step - loss: 6.3871 - acc: 0.5339 - val_loss: 2.8914 - val_acc: 0.5571\n",
      "Epoch 2/20\n",
      "8968/8968 [==============================] - 3s 374us/step - loss: 2.5435 - acc: 0.5767 - val_loss: 2.2683 - val_acc: 0.6004\n",
      "Epoch 3/20\n",
      "8968/8968 [==============================] - 3s 355us/step - loss: 2.2726 - acc: 0.5956 - val_loss: 2.1186 - val_acc: 0.6469\n",
      "Epoch 4/20\n",
      "8968/8968 [==============================] - 3s 383us/step - loss: 2.1939 - acc: 0.6257 - val_loss: 2.0629 - val_acc: 0.6659\n",
      "Epoch 5/20\n",
      "8968/8968 [==============================] - 3s 352us/step - loss: 2.1365 - acc: 0.6423 - val_loss: 2.0108 - val_acc: 0.6827\n",
      "Epoch 6/20\n",
      "8968/8968 [==============================] - 3s 345us/step - loss: 2.0988 - acc: 0.6481 - val_loss: 1.9698 - val_acc: 0.6898\n",
      "Epoch 7/20\n",
      "8968/8968 [==============================] - 3s 346us/step - loss: 2.0685 - acc: 0.6514 - val_loss: 1.9816 - val_acc: 0.6779\n",
      "Epoch 8/20\n",
      "8968/8968 [==============================] - 3s 345us/step - loss: 2.0607 - acc: 0.6484 - val_loss: 1.9603 - val_acc: 0.6885\n",
      "Epoch 9/20\n",
      "8968/8968 [==============================] - 3s 360us/step - loss: 2.0221 - acc: 0.6601 - val_loss: 1.9201 - val_acc: 0.6748\n",
      "Epoch 10/20\n",
      "8968/8968 [==============================] - 3s 355us/step - loss: 2.0112 - acc: 0.6580 - val_loss: 1.8878 - val_acc: 0.6894\n",
      "Epoch 11/20\n",
      "8968/8968 [==============================] - 3s 349us/step - loss: 2.0119 - acc: 0.6567 - val_loss: 1.8848 - val_acc: 0.6872\n",
      "Epoch 12/20\n",
      "8968/8968 [==============================] - 3s 337us/step - loss: 1.9935 - acc: 0.6617 - val_loss: 1.9328 - val_acc: 0.6907\n",
      "Epoch 13/20\n",
      "8968/8968 [==============================] - 3s 343us/step - loss: 1.9930 - acc: 0.6588 - val_loss: 1.8884 - val_acc: 0.6916\n",
      "Epoch 14/20\n",
      "8968/8968 [==============================] - 3s 360us/step - loss: 1.9801 - acc: 0.6639 - val_loss: 1.9132 - val_acc: 0.6912\n",
      "Epoch 15/20\n",
      "8968/8968 [==============================] - 3s 343us/step - loss: 1.9806 - acc: 0.6648 - val_loss: 1.9052 - val_acc: 0.6832\n",
      "Epoch 16/20\n",
      "8968/8968 [==============================] - 3s 355us/step - loss: 1.9888 - acc: 0.6654 - val_loss: 1.8979 - val_acc: 0.6929\n",
      "Epoch 17/20\n",
      "8968/8968 [==============================] - 3s 356us/step - loss: 1.9689 - acc: 0.6670 - val_loss: 1.8519 - val_acc: 0.6907\n",
      "Epoch 18/20\n",
      "8968/8968 [==============================] - 3s 351us/step - loss: 1.9527 - acc: 0.6676 - val_loss: 1.9200 - val_acc: 0.6836\n",
      "Epoch 19/20\n",
      "8968/8968 [==============================] - 3s 367us/step - loss: 1.9616 - acc: 0.6675 - val_loss: 1.8457 - val_acc: 0.6894\n",
      "Epoch 20/20\n",
      "8968/8968 [==============================] - 3s 364us/step - loss: 1.9502 - acc: 0.6659 - val_loss: 1.9031 - val_acc: 0.6903\n",
      "Fold no:2\n",
      "Train on 8986 samples, validate on 2242 samples\n",
      "Epoch 1/20\n",
      "8986/8986 [==============================] - 4s 465us/step - loss: 6.4537 - acc: 0.5303 - val_loss: 2.8888 - val_acc: 0.5754\n",
      "Epoch 2/20\n",
      "8986/8986 [==============================] - 3s 349us/step - loss: 2.5543 - acc: 0.5737 - val_loss: 2.2699 - val_acc: 0.5839\n",
      "Epoch 3/20\n",
      "8986/8986 [==============================] - 3s 357us/step - loss: 2.2878 - acc: 0.5925 - val_loss: 2.1346 - val_acc: 0.6186\n",
      "Epoch 4/20\n",
      "8986/8986 [==============================] - 3s 350us/step - loss: 2.2012 - acc: 0.6067 - val_loss: 2.0671 - val_acc: 0.6392\n",
      "Epoch 5/20\n",
      "8986/8986 [==============================] - 3s 347us/step - loss: 2.1632 - acc: 0.6194 - val_loss: 2.0375 - val_acc: 0.6490\n",
      "Epoch 6/20\n",
      "8986/8986 [==============================] - 3s 361us/step - loss: 2.1302 - acc: 0.6233 - val_loss: 1.9928 - val_acc: 0.6548\n",
      "Epoch 7/20\n",
      "8986/8986 [==============================] - 3s 358us/step - loss: 2.1049 - acc: 0.6270 - val_loss: 1.9855 - val_acc: 0.6557\n",
      "Epoch 8/20\n",
      "8986/8986 [==============================] - 3s 354us/step - loss: 2.0881 - acc: 0.6324 - val_loss: 1.9473 - val_acc: 0.6690\n",
      "Epoch 9/20\n",
      "8986/8986 [==============================] - 3s 352us/step - loss: 2.0744 - acc: 0.6381 - val_loss: 1.9405 - val_acc: 0.6610\n",
      "Epoch 10/20\n",
      "8986/8986 [==============================] - 3s 342us/step - loss: 2.0634 - acc: 0.6397 - val_loss: 1.9303 - val_acc: 0.6695\n",
      "Epoch 11/20\n",
      "8986/8986 [==============================] - 3s 373us/step - loss: 2.0553 - acc: 0.6458 - val_loss: 1.9463 - val_acc: 0.6659\n",
      "Epoch 12/20\n",
      "8986/8986 [==============================] - 4s 415us/step - loss: 2.0446 - acc: 0.6461 - val_loss: 1.8971 - val_acc: 0.6905\n",
      "Epoch 13/20\n",
      "8986/8986 [==============================] - 3s 365us/step - loss: 2.0411 - acc: 0.6470 - val_loss: 1.9207 - val_acc: 0.6855\n",
      "Epoch 14/20\n",
      "8986/8986 [==============================] - 3s 361us/step - loss: 2.0211 - acc: 0.6532 - val_loss: 1.9147 - val_acc: 0.6815\n",
      "Epoch 15/20\n",
      "8986/8986 [==============================] - 3s 353us/step - loss: 2.0334 - acc: 0.6589 - val_loss: 1.8923 - val_acc: 0.6864\n",
      "Epoch 16/20\n",
      "8986/8986 [==============================] - 3s 377us/step - loss: 2.0276 - acc: 0.6584 - val_loss: 1.8672 - val_acc: 0.6958\n",
      "Epoch 17/20\n",
      "8986/8986 [==============================] - 3s 338us/step - loss: 2.0149 - acc: 0.6627 - val_loss: 1.8745 - val_acc: 0.6855\n",
      "Epoch 18/20\n",
      "8986/8986 [==============================] - 3s 357us/step - loss: 1.9982 - acc: 0.6633 - val_loss: 1.8598 - val_acc: 0.6860\n",
      "Epoch 19/20\n",
      "8986/8986 [==============================] - 3s 354us/step - loss: 2.0224 - acc: 0.6649 - val_loss: 1.8807 - val_acc: 0.6855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "8986/8986 [==============================] - 3s 341us/step - loss: 2.0191 - acc: 0.6602 - val_loss: 1.8699 - val_acc: 0.6887\n",
      "Fold no:3\n",
      "Train on 8995 samples, validate on 2233 samples\n",
      "Epoch 1/20\n",
      "8995/8995 [==============================] - 5s 570us/step - loss: 6.2748 - acc: 0.5347 - val_loss: 2.7725 - val_acc: 0.6167\n",
      "Epoch 2/20\n",
      "8995/8995 [==============================] - 3s 379us/step - loss: 2.5367 - acc: 0.5959 - val_loss: 2.2462 - val_acc: 0.6435\n",
      "Epoch 3/20\n",
      "8995/8995 [==============================] - 3s 368us/step - loss: 2.2908 - acc: 0.6153 - val_loss: 2.1131 - val_acc: 0.6440\n",
      "Epoch 4/20\n",
      "8995/8995 [==============================] - 3s 388us/step - loss: 2.1948 - acc: 0.6318 - val_loss: 2.0176 - val_acc: 0.6597\n",
      "Epoch 5/20\n",
      "8995/8995 [==============================] - 5s 510us/step - loss: 2.1402 - acc: 0.6461 - val_loss: 2.0147 - val_acc: 0.6547\n",
      "Epoch 6/20\n",
      "8995/8995 [==============================] - 3s 386us/step - loss: 2.0974 - acc: 0.6529 - val_loss: 1.9375 - val_acc: 0.6856\n",
      "Epoch 7/20\n",
      "8995/8995 [==============================] - 4s 402us/step - loss: 2.0589 - acc: 0.6609 - val_loss: 1.9076 - val_acc: 0.6892\n",
      "Epoch 8/20\n",
      "8995/8995 [==============================] - 4s 483us/step - loss: 2.0525 - acc: 0.6610 - val_loss: 1.9428 - val_acc: 0.6816\n",
      "Epoch 9/20\n",
      "8995/8995 [==============================] - 4s 482us/step - loss: 2.0164 - acc: 0.6629 - val_loss: 1.8881 - val_acc: 0.6897\n",
      "Epoch 10/20\n",
      "8995/8995 [==============================] - 3s 350us/step - loss: 2.0116 - acc: 0.6641 - val_loss: 1.8603 - val_acc: 0.6901\n",
      "Epoch 11/20\n",
      "8995/8995 [==============================] - 3s 351us/step - loss: 1.9874 - acc: 0.6690 - val_loss: 1.8540 - val_acc: 0.6923\n",
      "Epoch 12/20\n",
      "8995/8995 [==============================] - 4s 422us/step - loss: 1.9965 - acc: 0.6650 - val_loss: 1.8898 - val_acc: 0.6776\n",
      "Epoch 13/20\n",
      "8995/8995 [==============================] - 3s 367us/step - loss: 2.0030 - acc: 0.6659 - val_loss: 1.8297 - val_acc: 0.6946\n",
      "Epoch 14/20\n",
      "8995/8995 [==============================] - 4s 455us/step - loss: 1.9700 - acc: 0.6671 - val_loss: 1.8206 - val_acc: 0.6901\n",
      "Epoch 15/20\n",
      "8995/8995 [==============================] - 3s 364us/step - loss: 1.9684 - acc: 0.6687 - val_loss: 1.8268 - val_acc: 0.6897\n",
      "Epoch 16/20\n",
      "8995/8995 [==============================] - 3s 370us/step - loss: 1.9693 - acc: 0.6687 - val_loss: 1.8175 - val_acc: 0.6968\n",
      "Epoch 17/20\n",
      "8995/8995 [==============================] - 3s 372us/step - loss: 1.9637 - acc: 0.6669 - val_loss: 1.8499 - val_acc: 0.6879\n",
      "Epoch 18/20\n",
      "8995/8995 [==============================] - 4s 442us/step - loss: 1.9492 - acc: 0.6714 - val_loss: 1.8018 - val_acc: 0.6892\n",
      "Epoch 19/20\n",
      "8995/8995 [==============================] - 3s 374us/step - loss: 1.9550 - acc: 0.6710 - val_loss: 1.8196 - val_acc: 0.6861\n",
      "Epoch 20/20\n",
      "8995/8995 [==============================] - 3s 384us/step - loss: 1.9570 - acc: 0.6719 - val_loss: 1.7842 - val_acc: 0.6928\n",
      "Fold no:4\n",
      "Train on 9004 samples, validate on 2224 samples\n",
      "Epoch 1/20\n",
      "9004/9004 [==============================] - 5s 557us/step - loss: 6.3904 - acc: 0.5442 - val_loss: 2.8103 - val_acc: 0.6151\n",
      "Epoch 2/20\n",
      "9004/9004 [==============================] - 3s 370us/step - loss: 2.5274 - acc: 0.6071 - val_loss: 2.2488 - val_acc: 0.6461\n",
      "Epoch 3/20\n",
      "9004/9004 [==============================] - 3s 352us/step - loss: 2.2585 - acc: 0.6291 - val_loss: 2.0940 - val_acc: 0.6493\n",
      "Epoch 4/20\n",
      "9004/9004 [==============================] - 4s 432us/step - loss: 2.1635 - acc: 0.6395 - val_loss: 2.0609 - val_acc: 0.6560\n",
      "Epoch 5/20\n",
      "9004/9004 [==============================] - 3s 375us/step - loss: 2.1190 - acc: 0.6445 - val_loss: 2.0285 - val_acc: 0.6610\n",
      "Epoch 6/20\n",
      "9004/9004 [==============================] - 5s 520us/step - loss: 2.0981 - acc: 0.6460 - val_loss: 1.9665 - val_acc: 0.6794\n",
      "Epoch 7/20\n",
      "9004/9004 [==============================] - 5s 506us/step - loss: 2.0728 - acc: 0.6474 - val_loss: 1.9435 - val_acc: 0.6749\n",
      "Epoch 8/20\n",
      "9004/9004 [==============================] - 5s 515us/step - loss: 2.0619 - acc: 0.6543 - val_loss: 1.9559 - val_acc: 0.6772\n",
      "Epoch 9/20\n",
      "9004/9004 [==============================] - 4s 437us/step - loss: 2.0530 - acc: 0.6596 - val_loss: 1.9111 - val_acc: 0.6839\n",
      "Epoch 10/20\n",
      "9004/9004 [==============================] - 4s 435us/step - loss: 2.0468 - acc: 0.6615 - val_loss: 1.9521 - val_acc: 0.6835\n",
      "Epoch 11/20\n",
      "9004/9004 [==============================] - 4s 443us/step - loss: 2.0210 - acc: 0.6582 - val_loss: 1.9211 - val_acc: 0.6803\n",
      "Epoch 12/20\n",
      "9004/9004 [==============================] - 4s 442us/step - loss: 2.0049 - acc: 0.6596 - val_loss: 1.8984 - val_acc: 0.6862\n",
      "Epoch 13/20\n",
      "9004/9004 [==============================] - 4s 438us/step - loss: 1.9855 - acc: 0.6669 - val_loss: 1.8660 - val_acc: 0.6902\n",
      "Epoch 14/20\n",
      "9004/9004 [==============================] - 4s 441us/step - loss: 1.9930 - acc: 0.6640 - val_loss: 1.8686 - val_acc: 0.6969\n",
      "Epoch 15/20\n",
      "9004/9004 [==============================] - 4s 441us/step - loss: 1.9884 - acc: 0.6657 - val_loss: 1.8538 - val_acc: 0.6938\n",
      "Epoch 16/20\n",
      "9004/9004 [==============================] - 4s 435us/step - loss: 1.9798 - acc: 0.6676 - val_loss: 1.8595 - val_acc: 0.6879\n",
      "Epoch 17/20\n",
      "9004/9004 [==============================] - 4s 441us/step - loss: 1.9644 - acc: 0.6683 - val_loss: 1.8505 - val_acc: 0.6933\n",
      "Epoch 18/20\n",
      "9004/9004 [==============================] - 4s 446us/step - loss: 1.9715 - acc: 0.6707 - val_loss: 1.8574 - val_acc: 0.6897\n",
      "Epoch 19/20\n",
      "9004/9004 [==============================] - 4s 444us/step - loss: 1.9645 - acc: 0.6691 - val_loss: 1.8380 - val_acc: 0.6924\n",
      "Epoch 20/20\n",
      "9004/9004 [==============================] - 4s 439us/step - loss: 1.9565 - acc: 0.6713 - val_loss: 1.8411 - val_acc: 0.6911\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "histories_per_fold = []\n",
    "# split training and validation sets\n",
    "for i, (train, test) in enumerate(kfold.split(X, Y)):\n",
    "    print(\"Fold no:{}\".format(i))\n",
    "    X_train = X[train]\n",
    "    X_test = X[test]\n",
    "    Y_test = pd.get_dummies(Y[test])\n",
    "    Y_train = pd.get_dummies(Y[train])\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, kernel_regularizer=l1(0.001), activation='relu', input_shape=(max_words,)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, kernel_regularizer=l1(0.001), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, kernel_regularizer=l1(0.001), activation='relu', input_shape=(max_words,)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(46, activation='softmax'))\n",
    "    model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, Y_train, epochs=20, batch_size=32, verbose=1, validation_data=(X_test,Y_test))\n",
    "    histories_per_fold.append(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_plot(histories_per_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments:\n",
    "Added one more layer with dropout:\n",
    "You can notice that cros-validated accuracy did not increase. Also it doesn't overfit but after 10th epoch the network does not learn further either. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold no:0\n",
      "Train on 8959 samples, validate on 2269 samples\n",
      "Epoch 1/30\n",
      "8959/8959 [==============================] - 3s 356us/step - loss: 3.6919 - acc: 0.6294 - val_loss: 2.1815 - val_acc: 0.6871\n",
      "Epoch 2/30\n",
      "8959/8959 [==============================] - 2s 239us/step - loss: 2.0090 - acc: 0.6919 - val_loss: 1.9734 - val_acc: 0.6972\n",
      "Epoch 3/30\n",
      "8959/8959 [==============================] - 2s 229us/step - loss: 1.8844 - acc: 0.7059 - val_loss: 1.8830 - val_acc: 0.7162\n",
      "Epoch 4/30\n",
      "8959/8959 [==============================] - 2s 235us/step - loss: 1.8262 - acc: 0.7151 - val_loss: 1.8361 - val_acc: 0.7259\n",
      "Epoch 5/30\n",
      "8959/8959 [==============================] - 2s 253us/step - loss: 1.7761 - acc: 0.7281 - val_loss: 1.8163 - val_acc: 0.7193\n",
      "Epoch 6/30\n",
      "8959/8959 [==============================] - 2s 268us/step - loss: 1.7444 - acc: 0.7395 - val_loss: 1.7611 - val_acc: 0.7528\n",
      "Epoch 7/30\n",
      "8959/8959 [==============================] - 2s 218us/step - loss: 1.7087 - acc: 0.7454 - val_loss: 1.7439 - val_acc: 0.7594\n",
      "Epoch 8/30\n",
      "8959/8959 [==============================] - 2s 232us/step - loss: 1.6837 - acc: 0.7497 - val_loss: 1.7134 - val_acc: 0.7607\n",
      "Epoch 9/30\n",
      "8959/8959 [==============================] - 2s 233us/step - loss: 1.6663 - acc: 0.7497 - val_loss: 1.6893 - val_acc: 0.7607\n",
      "Epoch 10/30\n",
      "8959/8959 [==============================] - 2s 239us/step - loss: 1.6440 - acc: 0.7553 - val_loss: 1.6678 - val_acc: 0.7585\n",
      "Epoch 11/30\n",
      "8959/8959 [==============================] - 2s 233us/step - loss: 1.6479 - acc: 0.7543 - val_loss: 1.6687 - val_acc: 0.7545\n",
      "Epoch 12/30\n",
      "8959/8959 [==============================] - 2s 229us/step - loss: 1.6140 - acc: 0.7572 - val_loss: 1.6585 - val_acc: 0.7625\n",
      "Epoch 13/30\n",
      "8959/8959 [==============================] - 2s 220us/step - loss: 1.6017 - acc: 0.7616 - val_loss: 1.6464 - val_acc: 0.7607\n",
      "Epoch 14/30\n",
      "8959/8959 [==============================] - 2s 220us/step - loss: 1.5895 - acc: 0.7617 - val_loss: 1.6740 - val_acc: 0.7602\n",
      "Epoch 15/30\n",
      "8959/8959 [==============================] - 2s 228us/step - loss: 1.5865 - acc: 0.7636 - val_loss: 1.6786 - val_acc: 0.7506\n",
      "Epoch 16/30\n",
      "8959/8959 [==============================] - 2s 224us/step - loss: 1.5863 - acc: 0.7602 - val_loss: 1.6306 - val_acc: 0.7660\n",
      "Epoch 17/30\n",
      "8959/8959 [==============================] - 2s 227us/step - loss: 1.5730 - acc: 0.7633 - val_loss: 1.6327 - val_acc: 0.7633\n",
      "Epoch 18/30\n",
      "8959/8959 [==============================] - 2s 220us/step - loss: 1.5790 - acc: 0.7600 - val_loss: 1.6242 - val_acc: 0.7730\n",
      "Epoch 19/30\n",
      "8959/8959 [==============================] - 2s 225us/step - loss: 1.5555 - acc: 0.7698 - val_loss: 1.6994 - val_acc: 0.7541\n",
      "Epoch 20/30\n",
      "8959/8959 [==============================] - 2s 228us/step - loss: 1.5596 - acc: 0.7647 - val_loss: 1.6066 - val_acc: 0.7730\n",
      "Epoch 21/30\n",
      "8959/8959 [==============================] - 2s 234us/step - loss: 1.5551 - acc: 0.7689 - val_loss: 1.5705 - val_acc: 0.7717\n",
      "Epoch 22/30\n",
      "8959/8959 [==============================] - 2s 237us/step - loss: 1.5413 - acc: 0.7672 - val_loss: 1.6324 - val_acc: 0.7713\n",
      "Epoch 23/30\n",
      "8959/8959 [==============================] - 2s 243us/step - loss: 1.5387 - acc: 0.7682 - val_loss: 1.6122 - val_acc: 0.7686\n",
      "Epoch 24/30\n",
      "8959/8959 [==============================] - 2s 240us/step - loss: 1.5500 - acc: 0.7619 - val_loss: 1.5923 - val_acc: 0.7743\n",
      "Epoch 25/30\n",
      "8959/8959 [==============================] - 2s 235us/step - loss: 1.5378 - acc: 0.7658 - val_loss: 1.6193 - val_acc: 0.7699\n",
      "Epoch 26/30\n",
      "8959/8959 [==============================] - 2s 241us/step - loss: 1.5368 - acc: 0.7704 - val_loss: 1.6794 - val_acc: 0.7673\n",
      "Epoch 27/30\n",
      "8959/8959 [==============================] - 2s 240us/step - loss: 1.5376 - acc: 0.7702 - val_loss: 1.6258 - val_acc: 0.7660\n",
      "Epoch 28/30\n",
      "8959/8959 [==============================] - 2s 239us/step - loss: 1.5279 - acc: 0.7737 - val_loss: 1.5704 - val_acc: 0.7757\n",
      "Epoch 29/30\n",
      "8959/8959 [==============================] - 2s 240us/step - loss: 1.5387 - acc: 0.7689 - val_loss: 1.6307 - val_acc: 0.7717\n",
      "Epoch 30/30\n",
      "8959/8959 [==============================] - 2s 241us/step - loss: 1.5242 - acc: 0.7724 - val_loss: 1.6474 - val_acc: 0.7660\n",
      "Fold no:1\n",
      "Train on 8968 samples, validate on 2260 samples\n",
      "Epoch 1/30\n",
      "8968/8968 [==============================] - 3s 317us/step - loss: 3.7442 - acc: 0.6318 - val_loss: 2.2076 - val_acc: 0.6934\n",
      "Epoch 2/30\n",
      "8968/8968 [==============================] - 2s 247us/step - loss: 2.0371 - acc: 0.6901 - val_loss: 1.8797 - val_acc: 0.7088\n",
      "Epoch 3/30\n",
      "8968/8968 [==============================] - 2s 237us/step - loss: 1.9053 - acc: 0.7076 - val_loss: 1.8250 - val_acc: 0.7186\n",
      "Epoch 4/30\n",
      "8968/8968 [==============================] - 2s 243us/step - loss: 1.8383 - acc: 0.7233 - val_loss: 1.7906 - val_acc: 0.7327\n",
      "Epoch 5/30\n",
      "8968/8968 [==============================] - 2s 242us/step - loss: 1.7900 - acc: 0.7320 - val_loss: 1.7414 - val_acc: 0.7407\n",
      "Epoch 6/30\n",
      "8968/8968 [==============================] - 2s 239us/step - loss: 1.7475 - acc: 0.7416 - val_loss: 1.7740 - val_acc: 0.7381\n",
      "Epoch 7/30\n",
      "8968/8968 [==============================] - 2s 238us/step - loss: 1.7323 - acc: 0.7448 - val_loss: 1.6972 - val_acc: 0.7509\n",
      "Epoch 8/30\n",
      "8968/8968 [==============================] - 2s 243us/step - loss: 1.7049 - acc: 0.7473 - val_loss: 1.6601 - val_acc: 0.7544\n",
      "Epoch 9/30\n",
      "8968/8968 [==============================] - 2s 246us/step - loss: 1.6855 - acc: 0.7559 - val_loss: 1.6857 - val_acc: 0.7469\n",
      "Epoch 10/30\n",
      "8968/8968 [==============================] - 2s 242us/step - loss: 1.6644 - acc: 0.7578 - val_loss: 1.6658 - val_acc: 0.7553\n",
      "Epoch 11/30\n",
      "8968/8968 [==============================] - 2s 242us/step - loss: 1.6443 - acc: 0.7580 - val_loss: 1.6581 - val_acc: 0.7606\n",
      "Epoch 12/30\n",
      "8968/8968 [==============================] - 2s 235us/step - loss: 1.6331 - acc: 0.7575 - val_loss: 1.6051 - val_acc: 0.7704\n",
      "Epoch 13/30\n",
      "8968/8968 [==============================] - 2s 236us/step - loss: 1.6355 - acc: 0.7615 - val_loss: 1.6544 - val_acc: 0.7650\n",
      "Epoch 14/30\n",
      "8968/8968 [==============================] - 2s 241us/step - loss: 1.6100 - acc: 0.7675 - val_loss: 1.6427 - val_acc: 0.7624\n",
      "Epoch 15/30\n",
      "8968/8968 [==============================] - 2s 247us/step - loss: 1.6050 - acc: 0.7664 - val_loss: 1.6487 - val_acc: 0.7575\n",
      "Epoch 16/30\n",
      "8968/8968 [==============================] - 2s 240us/step - loss: 1.6057 - acc: 0.7642 - val_loss: 1.5930 - val_acc: 0.7761\n",
      "Epoch 17/30\n",
      "8968/8968 [==============================] - 2s 247us/step - loss: 1.5984 - acc: 0.7659 - val_loss: 1.5635 - val_acc: 0.7743\n",
      "Epoch 18/30\n",
      "8968/8968 [==============================] - 2s 245us/step - loss: 1.5917 - acc: 0.7683 - val_loss: 1.5712 - val_acc: 0.7673\n",
      "Epoch 19/30\n",
      "8968/8968 [==============================] - 2s 249us/step - loss: 1.5908 - acc: 0.7700 - val_loss: 1.6228 - val_acc: 0.7681\n",
      "Epoch 20/30\n",
      "8968/8968 [==============================] - 2s 244us/step - loss: 1.5953 - acc: 0.7680 - val_loss: 1.6027 - val_acc: 0.7765\n",
      "Epoch 21/30\n",
      "8968/8968 [==============================] - 2s 243us/step - loss: 1.5771 - acc: 0.7717 - val_loss: 1.6302 - val_acc: 0.7708\n",
      "Epoch 22/30\n",
      "8968/8968 [==============================] - 2s 249us/step - loss: 1.5826 - acc: 0.7691 - val_loss: 1.6239 - val_acc: 0.7774\n",
      "Epoch 23/30\n",
      "8968/8968 [==============================] - 2s 247us/step - loss: 1.5622 - acc: 0.7742 - val_loss: 1.5909 - val_acc: 0.7686\n",
      "Epoch 24/30\n",
      "8968/8968 [==============================] - 2s 246us/step - loss: 1.5885 - acc: 0.7697 - val_loss: 1.5951 - val_acc: 0.7708\n",
      "Epoch 25/30\n",
      "8968/8968 [==============================] - 2s 251us/step - loss: 1.5708 - acc: 0.7741 - val_loss: 1.6235 - val_acc: 0.7792\n",
      "Epoch 26/30\n",
      "8968/8968 [==============================] - 2s 245us/step - loss: 1.5605 - acc: 0.7711 - val_loss: 1.5569 - val_acc: 0.7770\n",
      "Epoch 27/30\n",
      "8968/8968 [==============================] - 2s 246us/step - loss: 1.5620 - acc: 0.7704 - val_loss: 1.5524 - val_acc: 0.7779\n",
      "Epoch 28/30\n",
      "8968/8968 [==============================] - 2s 247us/step - loss: 1.5602 - acc: 0.7765 - val_loss: 1.5379 - val_acc: 0.7699\n",
      "Epoch 29/30\n",
      "8968/8968 [==============================] - 2s 251us/step - loss: 1.5416 - acc: 0.7781 - val_loss: 1.5696 - val_acc: 0.7743\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8968/8968 [==============================] - 2s 230us/step - loss: 1.5513 - acc: 0.7738 - val_loss: 1.6156 - val_acc: 0.7774\n",
      "Fold no:2\n",
      "Train on 8986 samples, validate on 2242 samples\n",
      "Epoch 1/30\n",
      "8986/8986 [==============================] - 3s 300us/step - loss: 3.7353 - acc: 0.6318 - val_loss: 2.1157 - val_acc: 0.6994\n",
      "Epoch 2/30\n",
      "8986/8986 [==============================] - 2s 224us/step - loss: 2.0317 - acc: 0.6899 - val_loss: 1.8984 - val_acc: 0.7056\n",
      "Epoch 3/30\n",
      "8986/8986 [==============================] - 2s 231us/step - loss: 1.8999 - acc: 0.7000 - val_loss: 1.8150 - val_acc: 0.7275\n",
      "Epoch 4/30\n",
      "8986/8986 [==============================] - 2s 225us/step - loss: 1.8451 - acc: 0.7147 - val_loss: 1.7631 - val_acc: 0.7391\n",
      "Epoch 5/30\n",
      "8986/8986 [==============================] - 2s 230us/step - loss: 1.7974 - acc: 0.7246 - val_loss: 1.7322 - val_acc: 0.7319\n",
      "Epoch 6/30\n",
      "8986/8986 [==============================] - 2s 227us/step - loss: 1.7589 - acc: 0.7369 - val_loss: 1.6898 - val_acc: 0.7484\n",
      "Epoch 7/30\n",
      "8986/8986 [==============================] - 2s 226us/step - loss: 1.7385 - acc: 0.7420 - val_loss: 1.6502 - val_acc: 0.7502\n",
      "Epoch 8/30\n",
      "8986/8986 [==============================] - 2s 230us/step - loss: 1.7167 - acc: 0.7429 - val_loss: 1.6205 - val_acc: 0.7574\n",
      "Epoch 9/30\n",
      "8986/8986 [==============================] - 2s 234us/step - loss: 1.6796 - acc: 0.7488 - val_loss: 1.6092 - val_acc: 0.7649\n",
      "Epoch 10/30\n",
      "8986/8986 [==============================] - 2s 238us/step - loss: 1.6706 - acc: 0.7550 - val_loss: 1.5918 - val_acc: 0.7632\n",
      "Epoch 11/30\n",
      "8986/8986 [==============================] - 2s 233us/step - loss: 1.6581 - acc: 0.7528 - val_loss: 1.6210 - val_acc: 0.7533\n",
      "Epoch 12/30\n",
      "8986/8986 [==============================] - 2s 231us/step - loss: 1.6394 - acc: 0.7545 - val_loss: 1.5906 - val_acc: 0.7627\n",
      "Epoch 13/30\n",
      "8986/8986 [==============================] - 2s 232us/step - loss: 1.6315 - acc: 0.7583 - val_loss: 1.6409 - val_acc: 0.7551\n",
      "Epoch 14/30\n",
      "8986/8986 [==============================] - 2s 230us/step - loss: 1.6241 - acc: 0.7596 - val_loss: 1.5928 - val_acc: 0.7609\n",
      "Epoch 15/30\n",
      "8986/8986 [==============================] - 2s 236us/step - loss: 1.6147 - acc: 0.7619 - val_loss: 1.5679 - val_acc: 0.7756\n",
      "Epoch 16/30\n",
      "8986/8986 [==============================] - 2s 229us/step - loss: 1.6194 - acc: 0.7590 - val_loss: 1.5288 - val_acc: 0.7721\n",
      "Epoch 17/30\n",
      "8986/8986 [==============================] - 2s 231us/step - loss: 1.6082 - acc: 0.7611 - val_loss: 1.5352 - val_acc: 0.7752\n",
      "Epoch 18/30\n",
      "8986/8986 [==============================] - 2s 234us/step - loss: 1.5888 - acc: 0.7674 - val_loss: 1.5714 - val_acc: 0.7578\n",
      "Epoch 19/30\n",
      "8986/8986 [==============================] - 2s 234us/step - loss: 1.5835 - acc: 0.7657 - val_loss: 1.5365 - val_acc: 0.7703\n",
      "Epoch 20/30\n",
      "8986/8986 [==============================] - 2s 232us/step - loss: 1.5766 - acc: 0.7682 - val_loss: 1.5374 - val_acc: 0.7783\n",
      "Epoch 21/30\n",
      "8986/8986 [==============================] - 2s 231us/step - loss: 1.5794 - acc: 0.7679 - val_loss: 1.5228 - val_acc: 0.7761\n",
      "Epoch 22/30\n",
      "8986/8986 [==============================] - 2s 233us/step - loss: 1.5815 - acc: 0.7696 - val_loss: 1.5928 - val_acc: 0.7538\n",
      "Epoch 23/30\n",
      "8986/8986 [==============================] - 2s 234us/step - loss: 1.5819 - acc: 0.7674 - val_loss: 1.4976 - val_acc: 0.7850\n",
      "Epoch 24/30\n",
      "8986/8986 [==============================] - 2s 231us/step - loss: 1.5663 - acc: 0.7693 - val_loss: 1.5400 - val_acc: 0.7783\n",
      "Epoch 25/30\n",
      "8986/8986 [==============================] - 2s 235us/step - loss: 1.5669 - acc: 0.7704 - val_loss: 1.5242 - val_acc: 0.7895\n",
      "Epoch 26/30\n",
      "8986/8986 [==============================] - 2s 236us/step - loss: 1.5579 - acc: 0.7701 - val_loss: 1.5234 - val_acc: 0.7819\n",
      "Epoch 27/30\n",
      "8986/8986 [==============================] - 2s 233us/step - loss: 1.5518 - acc: 0.7730 - val_loss: 1.5304 - val_acc: 0.7743\n",
      "Epoch 28/30\n",
      "8986/8986 [==============================] - 2s 232us/step - loss: 1.5609 - acc: 0.7696 - val_loss: 1.5090 - val_acc: 0.7859\n",
      "Epoch 29/30\n",
      "8986/8986 [==============================] - 2s 240us/step - loss: 1.5433 - acc: 0.7763 - val_loss: 1.4920 - val_acc: 0.7855\n",
      "Epoch 30/30\n",
      "8986/8986 [==============================] - 2s 232us/step - loss: 1.5561 - acc: 0.7706 - val_loss: 1.5032 - val_acc: 0.7832\n",
      "Fold no:3\n",
      "Train on 8995 samples, validate on 2233 samples\n",
      "Epoch 1/30\n",
      "8995/8995 [==============================] - 3s 318us/step - loss: 3.6850 - acc: 0.6278 - val_loss: 2.1297 - val_acc: 0.6758\n",
      "Epoch 2/30\n",
      "8995/8995 [==============================] - 2s 237us/step - loss: 2.0253 - acc: 0.6882 - val_loss: 1.9187 - val_acc: 0.6959\n",
      "Epoch 3/30\n",
      "8995/8995 [==============================] - 2s 242us/step - loss: 1.9032 - acc: 0.6986 - val_loss: 1.8013 - val_acc: 0.7125\n",
      "Epoch 4/30\n",
      "8995/8995 [==============================] - 2s 246us/step - loss: 1.8393 - acc: 0.7135 - val_loss: 1.7738 - val_acc: 0.7246\n",
      "Epoch 5/30\n",
      "8995/8995 [==============================] - 2s 246us/step - loss: 1.8030 - acc: 0.7298 - val_loss: 1.7244 - val_acc: 0.7510\n",
      "Epoch 6/30\n",
      "8995/8995 [==============================] - 2s 241us/step - loss: 1.7643 - acc: 0.7395 - val_loss: 1.6754 - val_acc: 0.7604\n",
      "Epoch 7/30\n",
      "8995/8995 [==============================] - 2s 247us/step - loss: 1.7361 - acc: 0.7410 - val_loss: 1.6459 - val_acc: 0.7555\n",
      "Epoch 8/30\n",
      "8995/8995 [==============================] - 2s 242us/step - loss: 1.7128 - acc: 0.7469 - val_loss: 1.6315 - val_acc: 0.7609\n",
      "Epoch 9/30\n",
      "8995/8995 [==============================] - 2s 247us/step - loss: 1.6894 - acc: 0.7513 - val_loss: 1.6480 - val_acc: 0.7618\n",
      "Epoch 10/30\n",
      "8995/8995 [==============================] - 2s 249us/step - loss: 1.6803 - acc: 0.7516 - val_loss: 1.5955 - val_acc: 0.7644\n",
      "Epoch 11/30\n",
      "8995/8995 [==============================] - 2s 248us/step - loss: 1.6611 - acc: 0.7549 - val_loss: 1.6079 - val_acc: 0.7613\n",
      "Epoch 12/30\n",
      "8995/8995 [==============================] - 2s 241us/step - loss: 1.6398 - acc: 0.7553 - val_loss: 1.5737 - val_acc: 0.7609\n",
      "Epoch 13/30\n",
      "8995/8995 [==============================] - 2s 248us/step - loss: 1.6392 - acc: 0.7589 - val_loss: 1.5675 - val_acc: 0.7694\n",
      "Epoch 14/30\n",
      "8995/8995 [==============================] - 2s 242us/step - loss: 1.6258 - acc: 0.7638 - val_loss: 1.5899 - val_acc: 0.7680\n",
      "Epoch 15/30\n",
      "8995/8995 [==============================] - 2s 250us/step - loss: 1.6172 - acc: 0.7613 - val_loss: 1.5728 - val_acc: 0.7689\n",
      "Epoch 16/30\n",
      "8995/8995 [==============================] - 2s 250us/step - loss: 1.6098 - acc: 0.7595 - val_loss: 1.6019 - val_acc: 0.7618\n",
      "Epoch 17/30\n",
      "8995/8995 [==============================] - 2s 254us/step - loss: 1.6040 - acc: 0.7638 - val_loss: 1.5264 - val_acc: 0.7738\n",
      "Epoch 18/30\n",
      "8995/8995 [==============================] - 2s 251us/step - loss: 1.6020 - acc: 0.7666 - val_loss: 1.5460 - val_acc: 0.7725\n",
      "Epoch 19/30\n",
      "8995/8995 [==============================] - 2s 247us/step - loss: 1.6016 - acc: 0.7641 - val_loss: 1.5267 - val_acc: 0.7779\n",
      "Epoch 20/30\n",
      "8995/8995 [==============================] - 2s 242us/step - loss: 1.5889 - acc: 0.7675 - val_loss: 1.5240 - val_acc: 0.7833\n",
      "Epoch 21/30\n",
      "8995/8995 [==============================] - 2s 252us/step - loss: 1.5833 - acc: 0.7686 - val_loss: 1.5593 - val_acc: 0.7738\n",
      "Epoch 22/30\n",
      "8995/8995 [==============================] - 2s 247us/step - loss: 1.5803 - acc: 0.7655 - val_loss: 1.5309 - val_acc: 0.7824\n",
      "Epoch 23/30\n",
      "8995/8995 [==============================] - 2s 249us/step - loss: 1.5661 - acc: 0.7689 - val_loss: 1.5645 - val_acc: 0.7694\n",
      "Epoch 24/30\n",
      "8995/8995 [==============================] - 2s 245us/step - loss: 1.5624 - acc: 0.7704 - val_loss: 1.5356 - val_acc: 0.7730\n",
      "Epoch 25/30\n",
      "8995/8995 [==============================] - 2s 256us/step - loss: 1.5626 - acc: 0.7712 - val_loss: 1.5570 - val_acc: 0.7846\n",
      "Epoch 26/30\n",
      "8995/8995 [==============================] - 2s 251us/step - loss: 1.5744 - acc: 0.7728 - val_loss: 1.5226 - val_acc: 0.7864\n",
      "Epoch 27/30\n",
      "8995/8995 [==============================] - 2s 251us/step - loss: 1.5699 - acc: 0.7695 - val_loss: 1.5138 - val_acc: 0.7837\n",
      "Epoch 28/30\n",
      "8995/8995 [==============================] - 2s 249us/step - loss: 1.5628 - acc: 0.7705 - val_loss: 1.5392 - val_acc: 0.7877\n",
      "Epoch 29/30\n",
      "8995/8995 [==============================] - 2s 232us/step - loss: 1.5596 - acc: 0.7722 - val_loss: 1.4957 - val_acc: 0.7877\n",
      "Epoch 30/30\n",
      "8995/8995 [==============================] - 2s 232us/step - loss: 1.5543 - acc: 0.7744 - val_loss: 1.5439 - val_acc: 0.7810\n",
      "Fold no:4\n",
      "Train on 9004 samples, validate on 2224 samples\n",
      "Epoch 1/30\n",
      "9004/9004 [==============================] - 3s 314us/step - loss: 3.6855 - acc: 0.6272 - val_loss: 2.1208 - val_acc: 0.6969\n",
      "Epoch 2/30\n",
      "9004/9004 [==============================] - 2s 232us/step - loss: 2.0232 - acc: 0.6875 - val_loss: 1.8915 - val_acc: 0.7019\n",
      "Epoch 3/30\n",
      "9004/9004 [==============================] - 2s 236us/step - loss: 1.8879 - acc: 0.7052 - val_loss: 1.8339 - val_acc: 0.7127\n",
      "Epoch 4/30\n",
      "9004/9004 [==============================] - 2s 231us/step - loss: 1.8309 - acc: 0.7165 - val_loss: 1.8190 - val_acc: 0.7217\n",
      "Epoch 5/30\n",
      "9004/9004 [==============================] - 2s 235us/step - loss: 1.7873 - acc: 0.7277 - val_loss: 1.7612 - val_acc: 0.7203\n",
      "Epoch 6/30\n",
      "9004/9004 [==============================] - 2s 237us/step - loss: 1.7567 - acc: 0.7347 - val_loss: 1.7120 - val_acc: 0.7334\n",
      "Epoch 7/30\n",
      "9004/9004 [==============================] - 2s 238us/step - loss: 1.7153 - acc: 0.7447 - val_loss: 1.6777 - val_acc: 0.7536\n",
      "Epoch 8/30\n",
      "9004/9004 [==============================] - 2s 231us/step - loss: 1.6903 - acc: 0.7469 - val_loss: 1.6657 - val_acc: 0.7621\n",
      "Epoch 9/30\n",
      "9004/9004 [==============================] - 2s 236us/step - loss: 1.6825 - acc: 0.7499 - val_loss: 1.6442 - val_acc: 0.7617\n",
      "Epoch 10/30\n",
      "9004/9004 [==============================] - 2s 232us/step - loss: 1.6586 - acc: 0.7501 - val_loss: 1.6069 - val_acc: 0.7698\n",
      "Epoch 11/30\n",
      "9004/9004 [==============================] - 2s 233us/step - loss: 1.6466 - acc: 0.7570 - val_loss: 1.6437 - val_acc: 0.7513\n",
      "Epoch 12/30\n",
      "9004/9004 [==============================] - 2s 235us/step - loss: 1.6207 - acc: 0.7617 - val_loss: 1.5989 - val_acc: 0.7666\n",
      "Epoch 13/30\n",
      "9004/9004 [==============================] - 2s 233us/step - loss: 1.6227 - acc: 0.7591 - val_loss: 1.6065 - val_acc: 0.7630\n",
      "Epoch 14/30\n",
      "9004/9004 [==============================] - 2s 233us/step - loss: 1.6133 - acc: 0.7629 - val_loss: 1.5846 - val_acc: 0.7653\n",
      "Epoch 15/30\n",
      "9004/9004 [==============================] - 2s 234us/step - loss: 1.6027 - acc: 0.7621 - val_loss: 1.5720 - val_acc: 0.7644\n",
      "Epoch 16/30\n",
      "9004/9004 [==============================] - 2s 236us/step - loss: 1.5982 - acc: 0.7653 - val_loss: 1.5555 - val_acc: 0.7725\n",
      "Epoch 17/30\n",
      "9004/9004 [==============================] - 2s 238us/step - loss: 1.5876 - acc: 0.7662 - val_loss: 1.5459 - val_acc: 0.7752\n",
      "Epoch 18/30\n",
      "9004/9004 [==============================] - 2s 235us/step - loss: 1.5859 - acc: 0.7642 - val_loss: 1.5627 - val_acc: 0.7680\n",
      "Epoch 19/30\n",
      "9004/9004 [==============================] - 2s 237us/step - loss: 1.5804 - acc: 0.7652 - val_loss: 1.5642 - val_acc: 0.7716\n",
      "Epoch 20/30\n",
      "9004/9004 [==============================] - 2s 241us/step - loss: 1.5737 - acc: 0.7667 - val_loss: 1.5591 - val_acc: 0.7761\n",
      "Epoch 21/30\n",
      "9004/9004 [==============================] - 2s 242us/step - loss: 1.5720 - acc: 0.7695 - val_loss: 1.5496 - val_acc: 0.7738\n",
      "Epoch 22/30\n",
      "9004/9004 [==============================] - 2s 240us/step - loss: 1.5586 - acc: 0.7684 - val_loss: 1.5586 - val_acc: 0.7698\n",
      "Epoch 23/30\n",
      "9004/9004 [==============================] - 2s 241us/step - loss: 1.5600 - acc: 0.7680 - val_loss: 1.5167 - val_acc: 0.7806\n",
      "Epoch 24/30\n",
      "9004/9004 [==============================] - 2s 246us/step - loss: 1.5635 - acc: 0.7680 - val_loss: 1.5175 - val_acc: 0.7779\n",
      "Epoch 25/30\n",
      "9004/9004 [==============================] - 2s 242us/step - loss: 1.5608 - acc: 0.7682 - val_loss: 1.5672 - val_acc: 0.7711\n",
      "Epoch 26/30\n",
      "9004/9004 [==============================] - 2s 243us/step - loss: 1.5483 - acc: 0.7673 - val_loss: 1.5555 - val_acc: 0.7747\n",
      "Epoch 27/30\n",
      "9004/9004 [==============================] - 2s 237us/step - loss: 1.5646 - acc: 0.7672 - val_loss: 1.5599 - val_acc: 0.7801\n",
      "Epoch 28/30\n",
      "9004/9004 [==============================] - 2s 238us/step - loss: 1.5575 - acc: 0.7725 - val_loss: 1.5449 - val_acc: 0.7752\n",
      "Epoch 29/30\n",
      "9004/9004 [==============================] - 2s 241us/step - loss: 1.5501 - acc: 0.7699 - val_loss: 1.5236 - val_acc: 0.7774\n",
      "Epoch 30/30\n",
      "9004/9004 [==============================] - 2s 245us/step - loss: 1.5390 - acc: 0.7689 - val_loss: 1.5720 - val_acc: 0.7752\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "histories_per_fold = []\n",
    "# split training and validation sets\n",
    "for i, (train, test) in enumerate(kfold.split(X, Y)):\n",
    "    print(\"Fold no:{}\".format(i))\n",
    "    X_train = X[train]\n",
    "    X_test = X[test]\n",
    "    Y_test = pd.get_dummies(Y[test])\n",
    "    Y_train = pd.get_dummies(Y[train])\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, kernel_regularizer=l1(0.001), activation='relu', input_shape=(max_words,)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(46, activation='softmax'))\n",
    "    model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, Y_train, epochs=30, batch_size=32, verbose=1, validation_data=(X_test,Y_test))\n",
    "    histories_per_fold.append(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 256)               256256    \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 46)                11822     \n",
      "=================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_plot(histories_per_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removed one layer:\n",
    "performance increased instantly. Again it does not seem to overfit and the model keeps learning even after 25th epoch though it slows down. \n",
    "The intuition is the problem is not very complex so that a smaller network is sufficient and it generalizes better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold no:0\n",
      "Train on 8959 samples, validate on 2269 samples\n",
      "Epoch 1/30\n",
      "8959/8959 [==============================] - 6s 695us/step - loss: 5.1321 - acc: 0.6352 - val_loss: 2.7155 - val_acc: 0.6624\n",
      "Epoch 2/30\n",
      "8959/8959 [==============================] - 6s 619us/step - loss: 2.5862 - acc: 0.6745 - val_loss: 2.5442 - val_acc: 0.6866\n",
      "Epoch 3/30\n",
      "8959/8959 [==============================] - 6s 618us/step - loss: 2.4570 - acc: 0.6918 - val_loss: 2.4489 - val_acc: 0.7135\n",
      "Epoch 4/30\n",
      "8959/8959 [==============================] - 6s 633us/step - loss: 2.3636 - acc: 0.7059 - val_loss: 2.3807 - val_acc: 0.7153\n",
      "Epoch 5/30\n",
      "8959/8959 [==============================] - 6s 632us/step - loss: 2.2932 - acc: 0.7130 - val_loss: 2.3301 - val_acc: 0.7245\n",
      "Epoch 6/30\n",
      "8959/8959 [==============================] - 6s 627us/step - loss: 2.2290 - acc: 0.7278 - val_loss: 2.3527 - val_acc: 0.6915\n",
      "Epoch 7/30\n",
      "8959/8959 [==============================] - 6s 634us/step - loss: 2.1835 - acc: 0.7364 - val_loss: 2.2439 - val_acc: 0.7369\n",
      "Epoch 8/30\n",
      "8959/8959 [==============================] - 6s 651us/step - loss: 2.1440 - acc: 0.7405 - val_loss: 2.1759 - val_acc: 0.7387\n",
      "Epoch 9/30\n",
      "8959/8959 [==============================] - 6s 643us/step - loss: 2.1152 - acc: 0.7486 - val_loss: 2.1263 - val_acc: 0.7506\n",
      "Epoch 10/30\n",
      "8959/8959 [==============================] - 6s 650us/step - loss: 2.0879 - acc: 0.7495 - val_loss: 2.1125 - val_acc: 0.7567\n",
      "Epoch 11/30\n",
      "8959/8959 [==============================] - 6s 646us/step - loss: 2.0669 - acc: 0.7550 - val_loss: 2.1432 - val_acc: 0.7576\n",
      "Epoch 12/30\n",
      "8959/8959 [==============================] - 6s 659us/step - loss: 2.0473 - acc: 0.7561 - val_loss: 2.1100 - val_acc: 0.7625\n",
      "Epoch 13/30\n",
      "8959/8959 [==============================] - 6s 655us/step - loss: 2.0301 - acc: 0.7614 - val_loss: 2.0896 - val_acc: 0.7616\n",
      "Epoch 14/30\n",
      "8959/8959 [==============================] - 6s 656us/step - loss: 2.0241 - acc: 0.7616 - val_loss: 2.0281 - val_acc: 0.7629\n",
      "Epoch 15/30\n",
      "8959/8959 [==============================] - 6s 650us/step - loss: 2.0125 - acc: 0.7600 - val_loss: 2.0599 - val_acc: 0.7664\n",
      "Epoch 16/30\n",
      "8959/8959 [==============================] - 6s 645us/step - loss: 2.0113 - acc: 0.7644 - val_loss: 2.1155 - val_acc: 0.7519\n",
      "Epoch 17/30\n",
      "8959/8959 [==============================] - 6s 655us/step - loss: 1.9929 - acc: 0.7630 - val_loss: 2.0239 - val_acc: 0.7669\n",
      "Epoch 18/30\n",
      "8959/8959 [==============================] - 6s 649us/step - loss: 1.9781 - acc: 0.7700 - val_loss: 2.0218 - val_acc: 0.7655\n",
      "Epoch 19/30\n",
      "8959/8959 [==============================] - 6s 649us/step - loss: 1.9792 - acc: 0.7608 - val_loss: 2.0538 - val_acc: 0.7585\n",
      "Epoch 20/30\n",
      "8959/8959 [==============================] - 6s 658us/step - loss: 1.9747 - acc: 0.7658 - val_loss: 2.0121 - val_acc: 0.7717\n",
      "Epoch 21/30\n",
      "8959/8959 [==============================] - 6s 656us/step - loss: 1.9688 - acc: 0.7665 - val_loss: 2.0605 - val_acc: 0.7580\n",
      "Epoch 22/30\n",
      "8959/8959 [==============================] - 6s 655us/step - loss: 1.9601 - acc: 0.7697 - val_loss: 2.0059 - val_acc: 0.7748\n",
      "Epoch 23/30\n",
      "8959/8959 [==============================] - 6s 657us/step - loss: 1.9450 - acc: 0.7694 - val_loss: 1.9985 - val_acc: 0.7726\n",
      "Epoch 24/30\n",
      "8959/8959 [==============================] - 6s 659us/step - loss: 1.9526 - acc: 0.7675 - val_loss: 2.0107 - val_acc: 0.7757\n",
      "Epoch 25/30\n",
      "8959/8959 [==============================] - 6s 661us/step - loss: 1.9483 - acc: 0.7688 - val_loss: 2.0602 - val_acc: 0.7664\n",
      "Epoch 26/30\n",
      "8959/8959 [==============================] - 6s 657us/step - loss: 1.9341 - acc: 0.7718 - val_loss: 2.0040 - val_acc: 0.7730\n",
      "Epoch 27/30\n",
      "8959/8959 [==============================] - 6s 665us/step - loss: 1.9401 - acc: 0.7681 - val_loss: 1.9539 - val_acc: 0.7823\n",
      "Epoch 28/30\n",
      "8959/8959 [==============================] - 6s 657us/step - loss: 1.9256 - acc: 0.7731 - val_loss: 2.0515 - val_acc: 0.7642\n",
      "Epoch 29/30\n",
      "8959/8959 [==============================] - 6s 676us/step - loss: 1.9284 - acc: 0.7688 - val_loss: 1.9723 - val_acc: 0.7796\n",
      "Epoch 30/30\n",
      "8959/8959 [==============================] - 7s 766us/step - loss: 1.9309 - acc: 0.7714 - val_loss: 2.0428 - val_acc: 0.7717\n",
      "Fold no:1\n",
      "Train on 8968 samples, validate on 2260 samples\n",
      "Epoch 1/30\n",
      "8968/8968 [==============================] - 8s 935us/step - loss: 5.1495 - acc: 0.6285 - val_loss: 2.6601 - val_acc: 0.6558\n",
      "Epoch 2/30\n",
      "8968/8968 [==============================] - 6s 634us/step - loss: 2.6027 - acc: 0.6735 - val_loss: 2.6667 - val_acc: 0.6429\n",
      "Epoch 3/30\n",
      "8968/8968 [==============================] - 7s 766us/step - loss: 2.4695 - acc: 0.6934 - val_loss: 2.3959 - val_acc: 0.6996\n",
      "Epoch 4/30\n",
      "8968/8968 [==============================] - 7s 747us/step - loss: 2.3766 - acc: 0.7056 - val_loss: 2.3773 - val_acc: 0.7066\n",
      "Epoch 5/30\n",
      "8968/8968 [==============================] - 6s 630us/step - loss: 2.3029 - acc: 0.7210 - val_loss: 2.3256 - val_acc: 0.7124\n",
      "Epoch 6/30\n",
      "8968/8968 [==============================] - 6s 702us/step - loss: 2.2574 - acc: 0.7257 - val_loss: 2.2470 - val_acc: 0.7301\n",
      "Epoch 7/30\n",
      "8968/8968 [==============================] - 6s 702us/step - loss: 2.1976 - acc: 0.7341 - val_loss: 2.3094 - val_acc: 0.6810\n",
      "Epoch 8/30\n",
      "8968/8968 [==============================] - 6s 641us/step - loss: 2.1575 - acc: 0.7441 - val_loss: 2.2214 - val_acc: 0.7358\n",
      "Epoch 9/30\n",
      "8968/8968 [==============================] - 8s 841us/step - loss: 2.1285 - acc: 0.7483 - val_loss: 2.0772 - val_acc: 0.7575\n",
      "Epoch 10/30\n",
      "8968/8968 [==============================] - 8s 850us/step - loss: 2.0978 - acc: 0.7533 - val_loss: 2.0664 - val_acc: 0.7478\n",
      "Epoch 11/30\n",
      "8968/8968 [==============================] - 7s 733us/step - loss: 2.0849 - acc: 0.7533 - val_loss: 2.1236 - val_acc: 0.7509\n",
      "Epoch 12/30\n",
      "8968/8968 [==============================] - 6s 683us/step - loss: 2.0622 - acc: 0.7570 - val_loss: 2.0360 - val_acc: 0.7611\n",
      "Epoch 13/30\n",
      "8968/8968 [==============================] - 6s 694us/step - loss: 2.0438 - acc: 0.7607 - val_loss: 2.0611 - val_acc: 0.7588\n",
      "Epoch 14/30\n",
      "8968/8968 [==============================] - 6s 716us/step - loss: 2.0423 - acc: 0.7614 - val_loss: 2.0707 - val_acc: 0.7690\n",
      "Epoch 15/30\n",
      "8968/8968 [==============================] - 7s 758us/step - loss: 2.0335 - acc: 0.7624 - val_loss: 2.0480 - val_acc: 0.7500\n",
      "Epoch 16/30\n",
      "8968/8968 [==============================] - 7s 732us/step - loss: 2.0122 - acc: 0.7588 - val_loss: 2.0174 - val_acc: 0.7673\n",
      "Epoch 17/30\n",
      "8968/8968 [==============================] - 6s 722us/step - loss: 2.0106 - acc: 0.7633 - val_loss: 1.9796 - val_acc: 0.7712\n",
      "Epoch 18/30\n",
      "8968/8968 [==============================] - 6s 724us/step - loss: 2.0015 - acc: 0.7659 - val_loss: 1.9654 - val_acc: 0.7677\n",
      "Epoch 19/30\n",
      "8968/8968 [==============================] - 7s 726us/step - loss: 1.9829 - acc: 0.7723 - val_loss: 2.0165 - val_acc: 0.7690\n",
      "Epoch 20/30\n",
      "8968/8968 [==============================] - 7s 730us/step - loss: 1.9822 - acc: 0.7692 - val_loss: 1.9523 - val_acc: 0.7748\n",
      "Epoch 21/30\n",
      "8968/8968 [==============================] - 7s 726us/step - loss: 1.9975 - acc: 0.7666 - val_loss: 1.9772 - val_acc: 0.7721\n",
      "Epoch 22/30\n",
      "8968/8968 [==============================] - 7s 732us/step - loss: 1.9751 - acc: 0.7690 - val_loss: 1.9844 - val_acc: 0.7721\n",
      "Epoch 23/30\n",
      "8968/8968 [==============================] - 7s 750us/step - loss: 1.9786 - acc: 0.7675 - val_loss: 1.9966 - val_acc: 0.7695\n",
      "Epoch 24/30\n",
      "8968/8968 [==============================] - 7s 730us/step - loss: 1.9734 - acc: 0.7707 - val_loss: 1.9687 - val_acc: 0.7726\n",
      "Epoch 25/30\n",
      "8968/8968 [==============================] - 7s 732us/step - loss: 1.9735 - acc: 0.7673 - val_loss: 1.9482 - val_acc: 0.7827\n",
      "Epoch 26/30\n",
      "8968/8968 [==============================] - 7s 732us/step - loss: 1.9571 - acc: 0.7741 - val_loss: 1.9474 - val_acc: 0.7774\n",
      "Epoch 27/30\n",
      "8968/8968 [==============================] - 7s 730us/step - loss: 1.9563 - acc: 0.7674 - val_loss: 1.9483 - val_acc: 0.7726\n",
      "Epoch 28/30\n",
      "8968/8968 [==============================] - 7s 730us/step - loss: 1.9549 - acc: 0.7706 - val_loss: 1.9610 - val_acc: 0.7757\n",
      "Epoch 29/30\n",
      "8968/8968 [==============================] - 7s 727us/step - loss: 1.9528 - acc: 0.7696 - val_loss: 1.9394 - val_acc: 0.7796\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8968/8968 [==============================] - 5s 611us/step - loss: 1.9425 - acc: 0.7722 - val_loss: 1.9927 - val_acc: 0.7770\n",
      "Fold no:2\n",
      "Train on 8986 samples, validate on 2242 samples\n",
      "Epoch 1/30\n",
      "8986/8986 [==============================] - 6s 708us/step - loss: 5.1446 - acc: 0.6273 - val_loss: 2.6100 - val_acc: 0.6704\n",
      "Epoch 2/30\n",
      "8986/8986 [==============================] - 5s 612us/step - loss: 2.6098 - acc: 0.6743 - val_loss: 2.5304 - val_acc: 0.6918\n",
      "Epoch 3/30\n",
      "8986/8986 [==============================] - 6s 615us/step - loss: 2.4748 - acc: 0.6861 - val_loss: 2.4167 - val_acc: 0.7043\n",
      "Epoch 4/30\n",
      "8986/8986 [==============================] - 6s 617us/step - loss: 2.3888 - acc: 0.7050 - val_loss: 2.2556 - val_acc: 0.7070\n",
      "Epoch 5/30\n",
      "8986/8986 [==============================] - 6s 615us/step - loss: 2.3246 - acc: 0.7142 - val_loss: 2.1705 - val_acc: 0.7328\n",
      "Epoch 6/30\n",
      "8986/8986 [==============================] - 6s 621us/step - loss: 2.2662 - acc: 0.7245 - val_loss: 2.2344 - val_acc: 0.7177\n",
      "Epoch 7/30\n",
      "8986/8986 [==============================] - 6s 682us/step - loss: 2.2099 - acc: 0.7375 - val_loss: 2.1677 - val_acc: 0.7221\n",
      "Epoch 8/30\n",
      "8986/8986 [==============================] - 7s 807us/step - loss: 2.1745 - acc: 0.7415 - val_loss: 2.1151 - val_acc: 0.7489\n",
      "Epoch 9/30\n",
      "8986/8986 [==============================] - 6s 670us/step - loss: 2.1497 - acc: 0.7456 - val_loss: 2.0918 - val_acc: 0.7600\n",
      "Epoch 10/30\n",
      "8986/8986 [==============================] - 6s 666us/step - loss: 2.1136 - acc: 0.7499 - val_loss: 2.0718 - val_acc: 0.7569\n",
      "Epoch 11/30\n",
      "8986/8986 [==============================] - 6s 662us/step - loss: 2.0942 - acc: 0.7501 - val_loss: 2.0439 - val_acc: 0.7605\n",
      "Epoch 12/30\n",
      "8986/8986 [==============================] - 6s 671us/step - loss: 2.0845 - acc: 0.7551 - val_loss: 2.0250 - val_acc: 0.7649\n",
      "Epoch 13/30\n",
      "8986/8986 [==============================] - 6s 667us/step - loss: 2.0734 - acc: 0.7528 - val_loss: 1.9779 - val_acc: 0.7716\n",
      "Epoch 14/30\n",
      "8986/8986 [==============================] - 6s 672us/step - loss: 2.0575 - acc: 0.7581 - val_loss: 2.0366 - val_acc: 0.7681\n",
      "Epoch 15/30\n",
      "8986/8986 [==============================] - 7s 737us/step - loss: 2.0437 - acc: 0.7556 - val_loss: 1.9606 - val_acc: 0.7752\n",
      "Epoch 16/30\n",
      "8986/8986 [==============================] - 6s 703us/step - loss: 2.0471 - acc: 0.7572 - val_loss: 1.9870 - val_acc: 0.7743\n",
      "Epoch 17/30\n",
      "8986/8986 [==============================] - 7s 726us/step - loss: 2.0328 - acc: 0.7590 - val_loss: 1.9830 - val_acc: 0.7739\n",
      "Epoch 18/30\n",
      "8986/8986 [==============================] - 6s 697us/step - loss: 2.0090 - acc: 0.7622 - val_loss: 1.9741 - val_acc: 0.7739\n",
      "Epoch 19/30\n",
      "8986/8986 [==============================] - 6s 699us/step - loss: 1.9966 - acc: 0.7667 - val_loss: 1.9552 - val_acc: 0.7837\n",
      "Epoch 20/30\n",
      "8986/8986 [==============================] - 6s 706us/step - loss: 1.9987 - acc: 0.7692 - val_loss: 1.9407 - val_acc: 0.7739\n",
      "Epoch 21/30\n",
      "8986/8986 [==============================] - 6s 703us/step - loss: 1.9917 - acc: 0.7684 - val_loss: 1.9349 - val_acc: 0.7752\n",
      "Epoch 22/30\n",
      "8986/8986 [==============================] - 6s 706us/step - loss: 1.9920 - acc: 0.7683 - val_loss: 1.9181 - val_acc: 0.7743\n",
      "Epoch 23/30\n",
      "8986/8986 [==============================] - 7s 776us/step - loss: 1.9752 - acc: 0.7696 - val_loss: 1.9383 - val_acc: 0.7748\n",
      "Epoch 24/30\n",
      "8986/8986 [==============================] - 7s 787us/step - loss: 1.9774 - acc: 0.7669 - val_loss: 1.9330 - val_acc: 0.7730\n",
      "Epoch 25/30\n",
      "8986/8986 [==============================] - 6s 716us/step - loss: 1.9643 - acc: 0.7718 - val_loss: 1.9673 - val_acc: 0.7645\n",
      "Epoch 26/30\n",
      "8986/8986 [==============================] - 6s 712us/step - loss: 1.9639 - acc: 0.7713 - val_loss: 1.8845 - val_acc: 0.7828\n",
      "Epoch 27/30\n",
      "8986/8986 [==============================] - 6s 716us/step - loss: 1.9543 - acc: 0.7702 - val_loss: 1.9258 - val_acc: 0.7814\n",
      "Epoch 28/30\n",
      "8986/8986 [==============================] - 6s 719us/step - loss: 1.9562 - acc: 0.7734 - val_loss: 1.9136 - val_acc: 0.7814\n",
      "Epoch 29/30\n",
      "8986/8986 [==============================] - 6s 714us/step - loss: 1.9495 - acc: 0.7720 - val_loss: 1.9487 - val_acc: 0.7774\n",
      "Epoch 30/30\n",
      "8986/8986 [==============================] - 6s 720us/step - loss: 1.9594 - acc: 0.7743 - val_loss: 1.9327 - val_acc: 0.7806\n",
      "Fold no:3\n",
      "Train on 8995 samples, validate on 2233 samples\n",
      "Epoch 1/30\n",
      "8995/8995 [==============================] - 7s 827us/step - loss: 5.1171 - acc: 0.6326 - val_loss: 2.6380 - val_acc: 0.6341\n",
      "Epoch 2/30\n",
      "8995/8995 [==============================] - 7s 729us/step - loss: 2.5993 - acc: 0.6749 - val_loss: 2.3583 - val_acc: 0.6910\n",
      "Epoch 3/30\n",
      "8995/8995 [==============================] - 7s 733us/step - loss: 2.4668 - acc: 0.6894 - val_loss: 2.2952 - val_acc: 0.7017\n",
      "Epoch 4/30\n",
      "8995/8995 [==============================] - 7s 791us/step - loss: 2.3874 - acc: 0.6981 - val_loss: 2.2002 - val_acc: 0.7143\n",
      "Epoch 5/30\n",
      "8995/8995 [==============================] - 7s 727us/step - loss: 2.3031 - acc: 0.7146 - val_loss: 2.2299 - val_acc: 0.7412\n",
      "Epoch 6/30\n",
      "8995/8995 [==============================] - 6s 715us/step - loss: 2.2532 - acc: 0.7294 - val_loss: 2.2152 - val_acc: 0.7228\n",
      "Epoch 7/30\n",
      "8995/8995 [==============================] - 7s 730us/step - loss: 2.2083 - acc: 0.7333 - val_loss: 2.1230 - val_acc: 0.7492\n",
      "Epoch 8/30\n",
      "8995/8995 [==============================] - 7s 729us/step - loss: 2.1701 - acc: 0.7397 - val_loss: 2.0808 - val_acc: 0.7483\n",
      "Epoch 9/30\n",
      "8995/8995 [==============================] - 7s 728us/step - loss: 2.1397 - acc: 0.7465 - val_loss: 2.0842 - val_acc: 0.7528\n",
      "Epoch 10/30\n",
      "8995/8995 [==============================] - 7s 771us/step - loss: 2.1143 - acc: 0.7465 - val_loss: 2.0574 - val_acc: 0.7600\n",
      "Epoch 11/30\n",
      "8995/8995 [==============================] - 7s 760us/step - loss: 2.0889 - acc: 0.7526 - val_loss: 2.0371 - val_acc: 0.7564\n",
      "Epoch 12/30\n",
      "8995/8995 [==============================] - 7s 793us/step - loss: 2.0838 - acc: 0.7540 - val_loss: 2.0591 - val_acc: 0.7515\n",
      "Epoch 13/30\n",
      "8995/8995 [==============================] - 7s 761us/step - loss: 2.0609 - acc: 0.7593 - val_loss: 2.0580 - val_acc: 0.7591\n",
      "Epoch 14/30\n",
      "8995/8995 [==============================] - 7s 737us/step - loss: 2.0578 - acc: 0.7570 - val_loss: 2.0080 - val_acc: 0.7685\n",
      "Epoch 15/30\n",
      "8995/8995 [==============================] - 7s 735us/step - loss: 2.0416 - acc: 0.7599 - val_loss: 1.9624 - val_acc: 0.7591\n",
      "Epoch 16/30\n",
      "8995/8995 [==============================] - 8s 936us/step - loss: 2.0209 - acc: 0.7611 - val_loss: 2.0053 - val_acc: 0.7653\n",
      "Epoch 17/30\n",
      "8995/8995 [==============================] - 7s 790us/step - loss: 2.0176 - acc: 0.7619 - val_loss: 1.9247 - val_acc: 0.7774\n",
      "Epoch 18/30\n",
      "8995/8995 [==============================] - 8s 904us/step - loss: 2.0174 - acc: 0.7609 - val_loss: 1.9932 - val_acc: 0.7618\n",
      "Epoch 19/30\n",
      "8995/8995 [==============================] - 6s 681us/step - loss: 2.0132 - acc: 0.7644 - val_loss: 1.9620 - val_acc: 0.7631\n",
      "Epoch 20/30\n",
      "8995/8995 [==============================] - 5s 610us/step - loss: 2.0071 - acc: 0.7631 - val_loss: 1.9433 - val_acc: 0.7761\n",
      "Epoch 21/30\n",
      "8995/8995 [==============================] - 5s 578us/step - loss: 1.9952 - acc: 0.7630 - val_loss: 1.8999 - val_acc: 0.7721\n",
      "Epoch 22/30\n",
      "8995/8995 [==============================] - 5s 593us/step - loss: 1.9919 - acc: 0.7635 - val_loss: 1.9240 - val_acc: 0.7716\n",
      "Epoch 23/30\n",
      "8995/8995 [==============================] - 5s 578us/step - loss: 1.9834 - acc: 0.7618 - val_loss: 1.8891 - val_acc: 0.7747\n",
      "Epoch 24/30\n",
      "8995/8995 [==============================] - 5s 584us/step - loss: 1.9859 - acc: 0.7641 - val_loss: 1.9615 - val_acc: 0.7662\n",
      "Epoch 25/30\n",
      "8995/8995 [==============================] - 5s 568us/step - loss: 1.9613 - acc: 0.7689 - val_loss: 1.9331 - val_acc: 0.7721\n",
      "Epoch 26/30\n",
      "8995/8995 [==============================] - 6s 617us/step - loss: 1.9635 - acc: 0.7653 - val_loss: 1.8922 - val_acc: 0.7819\n",
      "Epoch 27/30\n",
      "8995/8995 [==============================] - 5s 576us/step - loss: 1.9545 - acc: 0.7715 - val_loss: 1.9500 - val_acc: 0.7694\n",
      "Epoch 28/30\n",
      "8995/8995 [==============================] - 5s 573us/step - loss: 1.9534 - acc: 0.7709 - val_loss: 1.9077 - val_acc: 0.7792\n",
      "Epoch 29/30\n",
      "8995/8995 [==============================] - 5s 575us/step - loss: 1.9505 - acc: 0.7662 - val_loss: 1.9355 - val_acc: 0.7810\n",
      "Epoch 30/30\n",
      "8995/8995 [==============================] - 5s 606us/step - loss: 1.9621 - acc: 0.7696 - val_loss: 1.9030 - val_acc: 0.7743\n",
      "Fold no:4\n",
      "Train on 9004 samples, validate on 2224 samples\n",
      "Epoch 1/30\n",
      "9004/9004 [==============================] - 6s 673us/step - loss: 5.2103 - acc: 0.6274 - val_loss: 2.7911 - val_acc: 0.6740\n",
      "Epoch 2/30\n",
      "9004/9004 [==============================] - 6s 617us/step - loss: 2.6149 - acc: 0.6759 - val_loss: 2.5211 - val_acc: 0.6839\n",
      "Epoch 3/30\n",
      "9004/9004 [==============================] - 6s 629us/step - loss: 2.4871 - acc: 0.6858 - val_loss: 2.4335 - val_acc: 0.6893\n",
      "Epoch 4/30\n",
      "9004/9004 [==============================] - 7s 745us/step - loss: 2.3942 - acc: 0.6998 - val_loss: 2.3100 - val_acc: 0.7113\n",
      "Epoch 5/30\n",
      "9004/9004 [==============================] - 7s 728us/step - loss: 2.3275 - acc: 0.7128 - val_loss: 2.2170 - val_acc: 0.7226\n",
      "Epoch 6/30\n",
      "9004/9004 [==============================] - 6s 619us/step - loss: 2.2643 - acc: 0.7211 - val_loss: 2.2552 - val_acc: 0.7199\n",
      "Epoch 7/30\n",
      "9004/9004 [==============================] - 6s 621us/step - loss: 2.2157 - acc: 0.7295 - val_loss: 2.1647 - val_acc: 0.7473\n",
      "Epoch 8/30\n",
      "9004/9004 [==============================] - 6s 623us/step - loss: 2.1848 - acc: 0.7402 - val_loss: 2.1301 - val_acc: 0.7522\n",
      "Epoch 9/30\n",
      "9004/9004 [==============================] - 6s 649us/step - loss: 2.1514 - acc: 0.7438 - val_loss: 2.1065 - val_acc: 0.7500\n",
      "Epoch 10/30\n",
      "9004/9004 [==============================] - 6s 621us/step - loss: 2.1235 - acc: 0.7494 - val_loss: 2.1176 - val_acc: 0.7545\n",
      "Epoch 11/30\n",
      "9004/9004 [==============================] - 6s 615us/step - loss: 2.1041 - acc: 0.7501 - val_loss: 2.0784 - val_acc: 0.7531\n",
      "Epoch 12/30\n",
      "9004/9004 [==============================] - 6s 648us/step - loss: 2.0775 - acc: 0.7539 - val_loss: 2.0843 - val_acc: 0.7599\n",
      "Epoch 13/30\n",
      "9004/9004 [==============================] - 7s 774us/step - loss: 2.0748 - acc: 0.7561 - val_loss: 2.0905 - val_acc: 0.7621\n",
      "Epoch 14/30\n",
      "9004/9004 [==============================] - 7s 727us/step - loss: 2.0508 - acc: 0.7568 - val_loss: 2.0609 - val_acc: 0.7563\n",
      "Epoch 15/30\n",
      "9004/9004 [==============================] - 7s 725us/step - loss: 2.0363 - acc: 0.7599 - val_loss: 2.0405 - val_acc: 0.7590\n",
      "Epoch 16/30\n",
      "9004/9004 [==============================] - 7s 723us/step - loss: 2.0197 - acc: 0.7627 - val_loss: 2.0197 - val_acc: 0.7621\n",
      "Epoch 17/30\n",
      "9004/9004 [==============================] - 6s 677us/step - loss: 2.0175 - acc: 0.7633 - val_loss: 1.9924 - val_acc: 0.7711\n",
      "Epoch 18/30\n",
      "9004/9004 [==============================] - 6s 694us/step - loss: 2.0135 - acc: 0.7623 - val_loss: 2.0093 - val_acc: 0.7648\n",
      "Epoch 19/30\n",
      "9004/9004 [==============================] - 7s 775us/step - loss: 2.0092 - acc: 0.7639 - val_loss: 1.9498 - val_acc: 0.7801\n",
      "Epoch 20/30\n",
      "9004/9004 [==============================] - 7s 742us/step - loss: 1.9930 - acc: 0.7643 - val_loss: 1.9532 - val_acc: 0.7797\n",
      "Epoch 21/30\n",
      "9004/9004 [==============================] - 7s 724us/step - loss: 1.9975 - acc: 0.7668 - val_loss: 2.0437 - val_acc: 0.7684\n",
      "Epoch 22/30\n",
      "9004/9004 [==============================] - 7s 769us/step - loss: 1.9856 - acc: 0.7665 - val_loss: 1.9427 - val_acc: 0.7815\n",
      "Epoch 23/30\n",
      "9004/9004 [==============================] - 6s 690us/step - loss: 1.9839 - acc: 0.7668 - val_loss: 1.9443 - val_acc: 0.7810\n",
      "Epoch 24/30\n",
      "9004/9004 [==============================] - 6s 642us/step - loss: 1.9677 - acc: 0.7679 - val_loss: 1.9366 - val_acc: 0.7797\n",
      "Epoch 25/30\n",
      "9004/9004 [==============================] - 7s 791us/step - loss: 1.9837 - acc: 0.7665 - val_loss: 1.9497 - val_acc: 0.7846\n",
      "Epoch 26/30\n",
      "9004/9004 [==============================] - 6s 633us/step - loss: 1.9721 - acc: 0.7675 - val_loss: 2.1716 - val_acc: 0.7469\n",
      "Epoch 27/30\n",
      "9004/9004 [==============================] - 6s 629us/step - loss: 1.9650 - acc: 0.7701 - val_loss: 1.9850 - val_acc: 0.7711\n",
      "Epoch 28/30\n",
      "9004/9004 [==============================] - 7s 796us/step - loss: 1.9533 - acc: 0.7741 - val_loss: 1.9104 - val_acc: 0.7909\n",
      "Epoch 29/30\n",
      "9004/9004 [==============================] - 8s 862us/step - loss: 1.9530 - acc: 0.7700 - val_loss: 1.9067 - val_acc: 0.7846\n",
      "Epoch 30/30\n",
      "9004/9004 [==============================] - 8s 848us/step - loss: 1.9556 - acc: 0.7703 - val_loss: 1.9620 - val_acc: 0.7729\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "histories_per_fold = []\n",
    "# split training and validation sets\n",
    "for i, (train, test) in enumerate(kfold.split(X, Y)):\n",
    "    print(\"Fold no:{}\".format(i))\n",
    "    X_train = X[train]\n",
    "    X_test = X[test]\n",
    "    Y_test = pd.get_dummies(Y[test])\n",
    "    Y_train = pd.get_dummies(Y[train])\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(max_words, kernel_regularizer=l1(0.001), activation='relu', input_shape=(max_words,)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(46, activation='softmax'))\n",
    "    model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, Y_train, epochs=30, batch_size=32, verbose=1, validation_data=(X_test,Y_test))\n",
    "    histories_per_fold.append(history)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are 2 fully connected layers, the second one has to have 46 neurons so \n",
    "I increased number of neurons to the first one to input dimention. It did not really affect that much.\n",
    "It just slowed down. Probably former value was suffcient and adding more did not improve anything.\n",
    "Where dropout and l1 regularization prevented overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold no:0\n",
      "Train on 8959 samples, validate on 2269 samples\n",
      "Epoch 1/20\n",
      "8959/8959 [==============================] - 3s 317us/step - loss: 2.9004 - acc: 0.3322 - val_loss: 2.0806 - val_acc: 0.5046\n",
      "Epoch 2/20\n",
      "8959/8959 [==============================] - 1s 146us/step - loss: 2.1901 - acc: 0.4330 - val_loss: 1.8892 - val_acc: 0.5782\n",
      "Epoch 3/20\n",
      "8959/8959 [==============================] - 2s 208us/step - loss: 2.0411 - acc: 0.4658 - val_loss: 1.8099 - val_acc: 0.6082\n",
      "Epoch 4/20\n",
      "8959/8959 [==============================] - 1s 138us/step - loss: 1.9679 - acc: 0.4925 - val_loss: 1.7850 - val_acc: 0.6082\n",
      "Epoch 5/20\n",
      "8959/8959 [==============================] - 1s 111us/step - loss: 1.9274 - acc: 0.5068 - val_loss: 1.7421 - val_acc: 0.6302\n",
      "Epoch 6/20\n",
      "8959/8959 [==============================] - 2s 210us/step - loss: 1.8744 - acc: 0.5147 - val_loss: 1.7259 - val_acc: 0.6241\n",
      "Epoch 7/20\n",
      "8959/8959 [==============================] - 1s 165us/step - loss: 1.8499 - acc: 0.5232 - val_loss: 1.6998 - val_acc: 0.6421\n",
      "Epoch 8/20\n",
      "8959/8959 [==============================] - 1s 137us/step - loss: 1.8485 - acc: 0.5293 - val_loss: 1.6872 - val_acc: 0.6439\n",
      "Epoch 9/20\n",
      "8959/8959 [==============================] - 1s 155us/step - loss: 1.8371 - acc: 0.5306 - val_loss: 1.6910 - val_acc: 0.6395\n",
      "Epoch 10/20\n",
      "8959/8959 [==============================] - 2s 171us/step - loss: 1.8267 - acc: 0.5262 - val_loss: 1.6677 - val_acc: 0.6589\n",
      "Epoch 11/20\n",
      "8959/8959 [==============================] - 1s 115us/step - loss: 1.8154 - acc: 0.5296 - val_loss: 1.6685 - val_acc: 0.6523\n",
      "Epoch 12/20\n",
      "8959/8959 [==============================] - 1s 166us/step - loss: 1.8033 - acc: 0.5299 - val_loss: 1.6584 - val_acc: 0.6487\n",
      "Epoch 13/20\n",
      "8959/8959 [==============================] - 1s 143us/step - loss: 1.8006 - acc: 0.5294 - val_loss: 1.6508 - val_acc: 0.6558\n",
      "Epoch 14/20\n",
      "8959/8959 [==============================] - 1s 127us/step - loss: 1.7916 - acc: 0.5335 - val_loss: 1.6510 - val_acc: 0.6571\n",
      "Epoch 15/20\n",
      "8959/8959 [==============================] - 1s 123us/step - loss: 1.7796 - acc: 0.5387 - val_loss: 1.6484 - val_acc: 0.6501\n",
      "Epoch 16/20\n",
      "8959/8959 [==============================] - 1s 115us/step - loss: 1.7827 - acc: 0.5467 - val_loss: 1.6424 - val_acc: 0.6571\n",
      "Epoch 17/20\n",
      "8959/8959 [==============================] - 1s 119us/step - loss: 1.7742 - acc: 0.5439 - val_loss: 1.6399 - val_acc: 0.6620\n",
      "Epoch 18/20\n",
      "8959/8959 [==============================] - 1s 146us/step - loss: 1.7740 - acc: 0.5491 - val_loss: 1.6505 - val_acc: 0.6571\n",
      "Epoch 19/20\n",
      "8959/8959 [==============================] - 1s 167us/step - loss: 1.7755 - acc: 0.5460 - val_loss: 1.6442 - val_acc: 0.6580\n",
      "Epoch 20/20\n",
      "8959/8959 [==============================] - 2s 178us/step - loss: 1.7676 - acc: 0.5517 - val_loss: 1.6459 - val_acc: 0.6606\n",
      "Fold no:1\n",
      "Train on 8968 samples, validate on 2260 samples\n",
      "Epoch 1/20\n",
      "8968/8968 [==============================] - 3s 338us/step - loss: 2.7260 - acc: 0.4005 - val_loss: 1.9984 - val_acc: 0.5447\n",
      "Epoch 2/20\n",
      "8968/8968 [==============================] - 1s 166us/step - loss: 2.1275 - acc: 0.4924 - val_loss: 1.8393 - val_acc: 0.5637\n",
      "Epoch 3/20\n",
      "8968/8968 [==============================] - 1s 129us/step - loss: 2.0169 - acc: 0.4944 - val_loss: 1.7690 - val_acc: 0.5841\n",
      "Epoch 4/20\n",
      "8968/8968 [==============================] - 1s 123us/step - loss: 1.9715 - acc: 0.4998 - val_loss: 1.7314 - val_acc: 0.5973\n",
      "Epoch 5/20\n",
      "8968/8968 [==============================] - 2s 213us/step - loss: 1.9211 - acc: 0.5151 - val_loss: 1.6878 - val_acc: 0.6190\n",
      "Epoch 6/20\n",
      "8968/8968 [==============================] - 2s 182us/step - loss: 1.8923 - acc: 0.5187 - val_loss: 1.6563 - val_acc: 0.6416\n",
      "Epoch 7/20\n",
      "8968/8968 [==============================] - 1s 143us/step - loss: 1.8774 - acc: 0.5236 - val_loss: 1.6414 - val_acc: 0.6535\n",
      "Epoch 8/20\n",
      "8968/8968 [==============================] - 1s 143us/step - loss: 1.8433 - acc: 0.5302 - val_loss: 1.6200 - val_acc: 0.6708\n",
      "Epoch 9/20\n",
      "8968/8968 [==============================] - 1s 139us/step - loss: 1.8351 - acc: 0.5421 - val_loss: 1.5954 - val_acc: 0.6792\n",
      "Epoch 10/20\n",
      "8968/8968 [==============================] - 1s 142us/step - loss: 1.8234 - acc: 0.5393 - val_loss: 1.5786 - val_acc: 0.6774\n",
      "Epoch 11/20\n",
      "8968/8968 [==============================] - 1s 139us/step - loss: 1.8090 - acc: 0.5425 - val_loss: 1.5716 - val_acc: 0.6779\n",
      "Epoch 12/20\n",
      "8968/8968 [==============================] - 1s 138us/step - loss: 1.7908 - acc: 0.5432 - val_loss: 1.5502 - val_acc: 0.6783\n",
      "Epoch 13/20\n",
      "8968/8968 [==============================] - 1s 143us/step - loss: 1.7687 - acc: 0.5483 - val_loss: 1.5442 - val_acc: 0.6836\n",
      "Epoch 14/20\n",
      "8968/8968 [==============================] - 1s 142us/step - loss: 1.7780 - acc: 0.5496 - val_loss: 1.5424 - val_acc: 0.6774\n",
      "Epoch 15/20\n",
      "8968/8968 [==============================] - 1s 146us/step - loss: 1.7738 - acc: 0.5511 - val_loss: 1.5368 - val_acc: 0.6841\n",
      "Epoch 16/20\n",
      "8968/8968 [==============================] - 1s 146us/step - loss: 1.7729 - acc: 0.5527 - val_loss: 1.5380 - val_acc: 0.6823\n",
      "Epoch 17/20\n",
      "8968/8968 [==============================] - 1s 145us/step - loss: 1.7685 - acc: 0.5485 - val_loss: 1.5335 - val_acc: 0.6774\n",
      "Epoch 18/20\n",
      "8968/8968 [==============================] - 1s 146us/step - loss: 1.7645 - acc: 0.5541 - val_loss: 1.5291 - val_acc: 0.6814\n",
      "Epoch 19/20\n",
      "8968/8968 [==============================] - 1s 149us/step - loss: 1.7573 - acc: 0.5479 - val_loss: 1.5279 - val_acc: 0.6681\n",
      "Epoch 20/20\n",
      "8968/8968 [==============================] - 1s 147us/step - loss: 1.7658 - acc: 0.5511 - val_loss: 1.5387 - val_acc: 0.6659\n",
      "Fold no:2\n",
      "Train on 8986 samples, validate on 2242 samples\n",
      "Epoch 1/20\n",
      "8986/8986 [==============================] - 2s 254us/step - loss: 2.9220 - acc: 0.3678 - val_loss: 1.9687 - val_acc: 0.5731\n",
      "Epoch 2/20\n",
      "8986/8986 [==============================] - 1s 154us/step - loss: 2.1213 - acc: 0.4943 - val_loss: 1.7718 - val_acc: 0.5950\n",
      "Epoch 3/20\n",
      "8986/8986 [==============================] - 1s 149us/step - loss: 1.9933 - acc: 0.5097 - val_loss: 1.7108 - val_acc: 0.6111\n",
      "Epoch 4/20\n",
      "8986/8986 [==============================] - 1s 153us/step - loss: 1.9382 - acc: 0.5111 - val_loss: 1.6570 - val_acc: 0.6155\n",
      "Epoch 5/20\n",
      "8986/8986 [==============================] - 1s 151us/step - loss: 1.8985 - acc: 0.5152 - val_loss: 1.6231 - val_acc: 0.6249\n",
      "Epoch 6/20\n",
      "8986/8986 [==============================] - 1s 157us/step - loss: 1.8634 - acc: 0.5265 - val_loss: 1.6080 - val_acc: 0.6360\n",
      "Epoch 7/20\n",
      "8986/8986 [==============================] - 1s 155us/step - loss: 1.8538 - acc: 0.5253 - val_loss: 1.5832 - val_acc: 0.6503\n",
      "Epoch 8/20\n",
      "8986/8986 [==============================] - 1s 153us/step - loss: 1.8414 - acc: 0.5286 - val_loss: 1.5894 - val_acc: 0.6450\n",
      "Epoch 9/20\n",
      "8986/8986 [==============================] - 1s 154us/step - loss: 1.8265 - acc: 0.5248 - val_loss: 1.5707 - val_acc: 0.6414\n",
      "Epoch 10/20\n",
      "8986/8986 [==============================] - 1s 154us/step - loss: 1.8055 - acc: 0.5303 - val_loss: 1.5492 - val_acc: 0.6481\n",
      "Epoch 11/20\n",
      "8986/8986 [==============================] - 1s 156us/step - loss: 1.8069 - acc: 0.5364 - val_loss: 1.5431 - val_acc: 0.6396\n",
      "Epoch 12/20\n",
      "8986/8986 [==============================] - 1s 157us/step - loss: 1.7966 - acc: 0.5466 - val_loss: 1.5389 - val_acc: 0.6566\n",
      "Epoch 13/20\n",
      "8986/8986 [==============================] - 1s 156us/step - loss: 1.7894 - acc: 0.5493 - val_loss: 1.5377 - val_acc: 0.6615\n",
      "Epoch 14/20\n",
      "8986/8986 [==============================] - 1s 162us/step - loss: 1.7955 - acc: 0.5462 - val_loss: 1.5258 - val_acc: 0.6628\n",
      "Epoch 15/20\n",
      "8986/8986 [==============================] - 1s 164us/step - loss: 1.7791 - acc: 0.5509 - val_loss: 1.5095 - val_acc: 0.6806\n",
      "Epoch 16/20\n",
      "8986/8986 [==============================] - 1s 148us/step - loss: 1.7878 - acc: 0.5483 - val_loss: 1.5092 - val_acc: 0.6713\n",
      "Epoch 17/20\n",
      "8986/8986 [==============================] - 1s 159us/step - loss: 1.7865 - acc: 0.5467 - val_loss: 1.5077 - val_acc: 0.6748\n",
      "Epoch 18/20\n",
      "8986/8986 [==============================] - 1s 159us/step - loss: 1.7685 - acc: 0.5475 - val_loss: 1.5269 - val_acc: 0.6784\n",
      "Epoch 19/20\n",
      "8986/8986 [==============================] - 1s 162us/step - loss: 1.7696 - acc: 0.5519 - val_loss: 1.5035 - val_acc: 0.6820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "8986/8986 [==============================] - 1s 125us/step - loss: 1.7625 - acc: 0.5580 - val_loss: 1.5071 - val_acc: 0.6860\n",
      "Fold no:3\n",
      "Train on 8995 samples, validate on 2233 samples\n",
      "Epoch 1/20\n",
      "8995/8995 [==============================] - 2s 216us/step - loss: 2.7771 - acc: 0.4053 - val_loss: 1.9841 - val_acc: 0.5374\n",
      "Epoch 2/20\n",
      "8995/8995 [==============================] - 1s 111us/step - loss: 2.1755 - acc: 0.4599 - val_loss: 1.8323 - val_acc: 0.5387\n",
      "Epoch 3/20\n",
      "8995/8995 [==============================] - 1s 113us/step - loss: 2.0519 - acc: 0.4724 - val_loss: 1.7716 - val_acc: 0.5387\n",
      "Epoch 4/20\n",
      "8995/8995 [==============================] - 1s 115us/step - loss: 2.0070 - acc: 0.4716 - val_loss: 1.7292 - val_acc: 0.5414\n",
      "Epoch 5/20\n",
      "8995/8995 [==============================] - 1s 112us/step - loss: 1.9564 - acc: 0.4822 - val_loss: 1.6859 - val_acc: 0.5616\n",
      "Epoch 6/20\n",
      "8995/8995 [==============================] - 1s 112us/step - loss: 1.9339 - acc: 0.4835 - val_loss: 1.6614 - val_acc: 0.5777\n",
      "Epoch 7/20\n",
      "8995/8995 [==============================] - 1s 114us/step - loss: 1.8834 - acc: 0.4957 - val_loss: 1.6360 - val_acc: 0.5880\n",
      "Epoch 8/20\n",
      "8995/8995 [==============================] - 1s 114us/step - loss: 1.8806 - acc: 0.4978 - val_loss: 1.6175 - val_acc: 0.6001\n",
      "Epoch 9/20\n",
      "8995/8995 [==============================] - 1s 115us/step - loss: 1.8788 - acc: 0.4967 - val_loss: 1.6031 - val_acc: 0.5956\n",
      "Epoch 10/20\n",
      "8995/8995 [==============================] - 1s 111us/step - loss: 1.8528 - acc: 0.5042 - val_loss: 1.5839 - val_acc: 0.6117\n",
      "Epoch 11/20\n",
      "8995/8995 [==============================] - 1s 113us/step - loss: 1.8455 - acc: 0.5114 - val_loss: 1.5837 - val_acc: 0.6158\n",
      "Epoch 12/20\n",
      "8995/8995 [==============================] - 1s 116us/step - loss: 1.8274 - acc: 0.5164 - val_loss: 1.5639 - val_acc: 0.6131\n",
      "Epoch 13/20\n",
      "8995/8995 [==============================] - 1s 117us/step - loss: 1.8353 - acc: 0.5146 - val_loss: 1.5681 - val_acc: 0.6305\n",
      "Epoch 14/20\n",
      "8995/8995 [==============================] - 1s 117us/step - loss: 1.8265 - acc: 0.5187 - val_loss: 1.5538 - val_acc: 0.6305\n",
      "Epoch 15/20\n",
      "8995/8995 [==============================] - 1s 114us/step - loss: 1.8217 - acc: 0.5188 - val_loss: 1.5579 - val_acc: 0.6364\n",
      "Epoch 16/20\n",
      "8995/8995 [==============================] - 1s 112us/step - loss: 1.8214 - acc: 0.5216 - val_loss: 1.5439 - val_acc: 0.6337\n",
      "Epoch 17/20\n",
      "8995/8995 [==============================] - 1s 114us/step - loss: 1.8167 - acc: 0.5235 - val_loss: 1.5431 - val_acc: 0.6431\n",
      "Epoch 18/20\n",
      "8995/8995 [==============================] - 1s 115us/step - loss: 1.8065 - acc: 0.5264 - val_loss: 1.5392 - val_acc: 0.6364\n",
      "Epoch 19/20\n",
      "8995/8995 [==============================] - 1s 114us/step - loss: 1.8108 - acc: 0.5270 - val_loss: 1.5403 - val_acc: 0.6417\n",
      "Epoch 20/20\n",
      "8995/8995 [==============================] - 1s 115us/step - loss: 1.8080 - acc: 0.5315 - val_loss: 1.5417 - val_acc: 0.6417\n",
      "Fold no:4\n",
      "Train on 9004 samples, validate on 2224 samples\n",
      "Epoch 1/20\n",
      "9004/9004 [==============================] - 2s 218us/step - loss: 3.0122 - acc: 0.3657 - val_loss: 1.9615 - val_acc: 0.5760\n",
      "Epoch 2/20\n",
      "9004/9004 [==============================] - 1s 114us/step - loss: 2.1465 - acc: 0.5016 - val_loss: 1.7530 - val_acc: 0.6196\n",
      "Epoch 3/20\n",
      "9004/9004 [==============================] - 1s 113us/step - loss: 2.0038 - acc: 0.5161 - val_loss: 1.6668 - val_acc: 0.6434\n",
      "Epoch 4/20\n",
      "9004/9004 [==============================] - 1s 115us/step - loss: 1.9364 - acc: 0.5223 - val_loss: 1.6202 - val_acc: 0.6641\n",
      "Epoch 5/20\n",
      "9004/9004 [==============================] - 1s 113us/step - loss: 1.9013 - acc: 0.5405 - val_loss: 1.5997 - val_acc: 0.6587\n",
      "Epoch 6/20\n",
      "9004/9004 [==============================] - 1s 114us/step - loss: 1.8641 - acc: 0.5396 - val_loss: 1.5782 - val_acc: 0.6691\n",
      "Epoch 7/20\n",
      "9004/9004 [==============================] - 1s 116us/step - loss: 1.8565 - acc: 0.5381 - val_loss: 1.5716 - val_acc: 0.6686\n",
      "Epoch 8/20\n",
      "9004/9004 [==============================] - 1s 115us/step - loss: 1.8251 - acc: 0.5429 - val_loss: 1.5452 - val_acc: 0.6632\n",
      "Epoch 9/20\n",
      "9004/9004 [==============================] - 1s 116us/step - loss: 1.8107 - acc: 0.5525 - val_loss: 1.5379 - val_acc: 0.6731\n",
      "Epoch 10/20\n",
      "9004/9004 [==============================] - 1s 117us/step - loss: 1.7931 - acc: 0.5573 - val_loss: 1.5104 - val_acc: 0.6799\n",
      "Epoch 11/20\n",
      "9004/9004 [==============================] - 1s 117us/step - loss: 1.7945 - acc: 0.5538 - val_loss: 1.5044 - val_acc: 0.6857\n",
      "Epoch 12/20\n",
      "9004/9004 [==============================] - 1s 115us/step - loss: 1.7756 - acc: 0.5552 - val_loss: 1.5082 - val_acc: 0.6799\n",
      "Epoch 13/20\n",
      "9004/9004 [==============================] - 1s 115us/step - loss: 1.7915 - acc: 0.5553 - val_loss: 1.5047 - val_acc: 0.6853\n",
      "Epoch 14/20\n",
      "9004/9004 [==============================] - 1s 114us/step - loss: 1.7684 - acc: 0.5605 - val_loss: 1.5050 - val_acc: 0.6830\n",
      "Epoch 15/20\n",
      "9004/9004 [==============================] - 1s 115us/step - loss: 1.7734 - acc: 0.5586 - val_loss: 1.5052 - val_acc: 0.6794\n",
      "Epoch 16/20\n",
      "9004/9004 [==============================] - 1s 120us/step - loss: 1.7715 - acc: 0.5556 - val_loss: 1.5167 - val_acc: 0.6776\n",
      "Epoch 17/20\n",
      "9004/9004 [==============================] - 1s 115us/step - loss: 1.7623 - acc: 0.5579 - val_loss: 1.4859 - val_acc: 0.6862\n",
      "Epoch 18/20\n",
      "9004/9004 [==============================] - 1s 115us/step - loss: 1.7657 - acc: 0.5625 - val_loss: 1.4917 - val_acc: 0.6776\n",
      "Epoch 19/20\n",
      "9004/9004 [==============================] - 1s 117us/step - loss: 1.7542 - acc: 0.5623 - val_loss: 1.4861 - val_acc: 0.6871\n",
      "Epoch 20/20\n",
      "9004/9004 [==============================] - 1s 120us/step - loss: 1.7554 - acc: 0.5602 - val_loss: 1.4816 - val_acc: 0.6821\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cvscores = []\n",
    "histories_per_fold = []\n",
    "# split training and validation sets\n",
    "for i, (train, test) in enumerate(kfold.split(X, Y)):\n",
    "    print(\"Fold no:{}\".format(i))\n",
    "    X_train = X[train]\n",
    "    X_test = X[test]\n",
    "    Y_test = pd.get_dummies(Y[test])\n",
    "    Y_train = pd.get_dummies(Y[train])\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, kernel_regularizer=l1(0.001), activation='relu', input_shape=(max_words,)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(46, activation='softmax'))\n",
    "    model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, Y_train, epochs=20, batch_size=32, verbose=1, validation_data=(X_test,Y_test))\n",
    "    histories_per_fold.append(history)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_plot(histories_per_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly decreasing number of units drastically decreases accuracy effectively.\n",
    "But in my experiments even with 64 units in the first layer did similar to 256.\n",
    "\n",
    "The rule of thumb is that hidden layers usually should have number of units between the input \n",
    "dimention and output dimetion do. Which I found to be quite intuitive because we would like the layers \n",
    "to learn more and more abstract features which are less in number compared to lower level features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_cmpe597_tf_keras",
   "language": "python",
   "name": "dl_cmpe597_tf_keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
